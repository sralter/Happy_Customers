{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09482650-b3d5-4bdc-9376-912fa337238a",
   "metadata": {},
   "source": [
    "# HappyCustomer - An Apziva Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc6cc16-c3c5-46ac-ad8d-35ea83e4be53",
   "metadata": {},
   "source": [
    "By Samuel Alter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b438303-116f-483c-b218-b7348beda729",
   "metadata": {},
   "source": [
    "This project centers on a customer survey dataset from a delivery company. The dataset consists of the following:\n",
    "* `Y`: The target attribute, indicating whether the customer noted their happiness or unhappiness\n",
    "* `X1`: Order was delivered on time\n",
    "* `X2`: Contents of the order was as expected\n",
    "* `X3`: I ordered everything that I wanted to order\n",
    "* `X4`: I paid a good price for my order\n",
    "* `X5`: I am satisfied with my courier\n",
    "* `X6`: The app makes ordering easy for me\n",
    "\n",
    "Attributes `X1` through `X6` are on a 1 to 5 scale, with 5 indicating most agreement with the statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6761ac48-5842-435d-aa47-8bd099214770",
   "metadata": {},
   "source": [
    "The goals of this project are to train a model that predicts whether a customer is happy or not, based on their answers to the survey. Specifically, I am to reach 73% accuracy or higher with my modeling, or explain why my solution is superior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bccb0cf-a9fc-4b3d-9347-299b3af6595a",
   "metadata": {},
   "source": [
    "A stretch goal would be to determine which features are more important when predicting a customer's happiness. What is the minimal set of attributes or features that would preserve the most information about the problem, while at the same time increasing predictability? The aim here is to see if any question can be eliminated in the next survey round.\n",
    "\n",
    "The statistical analysis of the features can be found in the [Statistical Modeling](#statistical_modeling) section at the end of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c393b3-1d1a-417f-bbe7-ecc0dac7c82d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a85940-53be-40bb-9dc6-7a5ab6bc2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074b8d8-7d25-45db-8a58-39df5dede5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/ACME-HappinessSurvey2020.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48212e82-f0fe-4095-865d-fcb3995b78b7",
   "metadata": {},
   "source": [
    "Let's rename the columns to make them more intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae1131-5011-4b45-af2c-99c1b872cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "# using alphabet prefixes to ensure correct order of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4024f-59bc-4d3e-8bfc-9105cd5d038b",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd086b-6948-4487-a8aa-51b50b2dafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fe716-b036-49bb-ad5b-159fa4095cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986a0db-59e8-4900-8caa-6c73ac59128f",
   "metadata": {},
   "source": [
    "It seems like most of the participants in the survey were happy about the time it took to receive the order and app experience, but all of this will require more exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f095e8-6a8d-472e-a762-12969fb7c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2750ab-a44c-4704-8a35-8ecdee8b9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data labels\n",
    "x=[0,1]\n",
    "y=[df['y'].value_counts()[0],df['y'].value_counts()[1]]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax=sns.countplot(data=df, x='y',zorder=3,)\n",
    "plt.title('Distribution of Customer Happiness in Target (y)')\n",
    "plt.xlabel('Target Values\\n0: Unhappy, 1: Happy')\n",
    "plt.ylabel('Count')\n",
    "ax.yaxis.grid(True,zorder=0)\n",
    "for i in range(len(x)):\n",
    "    plt.text(i, y[i], y[i], ha = 'center')\n",
    "plt.savefig('../figs/1_ydistribution.pdf')\n",
    "plt.savefig('../figs/1_ydistribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465dda52-bd62-4ba9-ba2c-a2a17a1991c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In the dataset, {round(df['y'].value_counts()[1]/df['y'].shape[0]*100,2)}% of respondents were happy,\\nwhile {round(df['y'].value_counts()[0]/df['y'].shape[0]*100,0)}% of respondents were unhappy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec1076-4028-42de-b776-81cb795f1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare X data for plotting\n",
    "col_list=[]\n",
    "\n",
    "for i in df.columns:\n",
    "    col_list.append(i)\n",
    "    \n",
    "col_list.remove('y')\n",
    "\n",
    "df_melted=df.melt(value_vars=col_list,var_name='Variable',value_name='Value')\n",
    "\n",
    "# calculate mean value per variable\n",
    "mean_values=df_melted.groupby('Variable')['Value'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452faf25-0051-410f-97b7-300825134d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681b921-5257-4441-911b-ce9812bc44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom labels for following figure\n",
    "labels=[f\"{variable}: {mean_values[variable]:.2f}\" for variable in mean_values.keys()]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32873226-c673-459d-9e9f-d3a4a3aad3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted['Variable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f2f862-283f-454c-aefe-d42cd616c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabs=['Delivery Time',\n",
    "       'Contents of Order',\n",
    "       'Order Completeness',\n",
    "       'Price for Order',\n",
    "       'Satisfaction with Courier',\n",
    "       'Satisfaction with App Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38765a-6790-4792-8030-c4fbe65e1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of survey results\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax=sns.countplot(data=df_melted,x='Variable',hue='Value')\n",
    "plt.suptitle('Count of Survey Results for Each Survey Question\\n1 being least satisfied and 5 being most satisfied')\n",
    "plt.xlabel('Survey Question')\n",
    "plt.ylabel('Count')\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(True,which='major')\n",
    "ax.set_xticklabels(xlabs)\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend(title='Response',loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figs/1_xdistribution.pdf')\n",
    "plt.savefig('./figs/1_xdistribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63ad03-469a-4b65-99b2-0e4c970715a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup labels for mean values\n",
    "\n",
    "mean_values=df_melted.groupby('Variable')['Value'].mean()\n",
    "mean_values=mean_values.round(decimals=2)\n",
    "mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726fa6a-76f8-452d-b8fa-207f698c73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data labels\n",
    "x=[i for i in np.arange(6)]\n",
    "y=[mean_values[i] for i in np.arange(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98979b-df82-4934-b516-c332c9cd3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax=sns.barplot(data=df_melted,x='Variable',y='Value',ci=None,color='coral')\n",
    "plt.tight_layout(pad=10)\n",
    "# plot labels\n",
    "for i in range(len(x)):\n",
    "    plt.text(i, y[i], y[i], ha='center')\n",
    "ax.set_xticklabels(xlabs,rotation=30)\n",
    "ax.set_title('Mean Response to Survey Question')\n",
    "ax.set_ylabel('Mean Response')\n",
    "ax.set_xlabel('Survey Question')\n",
    "plt.savefig('./figs/1_xmeandistribution.pdf')\n",
    "plt.savefig('./figs/1_xmeandistribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb909a-7fad-4779-9a4a-e2d10cd7d413",
   "metadata": {},
   "source": [
    "The delivery time and app experience had the highest mean satisfaction in the survey, with the contents having the lowest overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b4834a-8b39-4225-8a20-42e842ff6dd2",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d491e-06c2-40c8-b418-b229c9398169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f,ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "# cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, annot=True,\n",
    "            cbar_kws={\"shrink\": .5})\n",
    "plt.title('Correlation Matrix\\nHigher absolute value indicates stronger correlation')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save fig\n",
    "plt.savefig('./figs/1_corrmatrix.pdf')\n",
    "plt.savefig('./figs/1_corrmatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f49b1a-f78a-439b-8222-68f87b16ffbb",
   "metadata": {},
   "source": [
    "The results of the correlation matrix shows that generally speaking, if one aspect of the experience is positive, the customer will rate others positive as well. One interesting correlation to highlight is the courier and time are connected, which makes sense: the courier is the person that gives you your order, and if the courier is on time you probably will rate the courier highly too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a540cef-234a-4fa0-ad55-40c260c7bdb9",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096d777-ee4c-4bfc-8c40-31e8da354f83",
   "metadata": {},
   "source": [
    "Remember, our target accuracy is to be greater than or equal to 73%. The accuracy floor we need to surpass is 55%, which is the amount of happy customers in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63452e6-2114-4a82-83e6-b47a9dee4ee1",
   "metadata": {},
   "source": [
    "Our target variable is `y`. Our independent variables, or features, are `X1`-`X6` (delivery time, contents of order, order completeness, price for order, satisfaction with courier, and satisfaction with app experience, respectively)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56488f1-e668-4ea0-9b28-225e7eeeb765",
   "metadata": {},
   "source": [
    "### Note on modeling method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad691350-cf6f-45b5-b20e-ce72bdf7382f",
   "metadata": {},
   "source": [
    "Our target variable is binary in that the customer notes whether they are happy or not. Thus, we will be using **logistic regression** models as they will predict a yes or no, 0 or 1, happy or not happy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2f4a1-45b9-48c0-a61f-34051692e59c",
   "metadata": {},
   "source": [
    "### Setting up `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49896d-7433-4f4d-8337-050762aefe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['y'],axis=1).to_numpy() # independent variables\n",
    "y=df[[col for col in df.columns if col == 'y']].to_numpy() # dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cb10d-5c33-4bee-9f98-eca875e100c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b982fa9d-85d0-49dc-80c3-1b31f072616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the independent variables: {X.shape}\")\n",
    "print(f\"The shape of the dependent variable:   {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7dc20a-dc40-4d98-bd77-34554ff1d838",
   "metadata": {},
   "source": [
    "Now we must transform the dependent variable into a vector to prepare it for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8f21b-ff45-4dc7-8b91-9c5bdfc4c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(-1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b82117-5318-47de-a50d-7be4db1d4079",
   "metadata": {},
   "source": [
    "### Basic `sklearn` Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7dcbf3-ffa3-4242-ad85-a45e099140f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730d27f-df6e-4428-bc88-4310271df665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X,y)\n",
    "\n",
    "# score the model\n",
    "logreg.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c89b2-be8a-4125-a96f-3915ba576a72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# intercept\n",
    "intercept = logreg.intercept_\n",
    "\n",
    "# coefficient\n",
    "coefficient = logreg.coef_[0]\n",
    "\n",
    "print(f'Intercept: {intercept}')\n",
    "print(f'Coefficients: {coefficient}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53f298-6ca6-4111-95bf-e5e67a137628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The accuracy of the basic logistic regression model is {round(logreg.score(X,y)*100,2)}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192fda7-50b0-4223-a7cd-5b6b2cd9f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The floor is {round(y.sum()/y.shape[0]*100,2)}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b7605-dbb6-4c06-a4ec-cf158166f71b",
   "metadata": {},
   "source": [
    "Although the model posted a higher accuracy than the basic structure of the datset, we have a long way to go still."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35227e-e02d-495e-872e-aacc33613406",
   "metadata": {},
   "source": [
    "### Second attempt: Using Train/Test Split, `stratify`, and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44da0655-e5ae-4187-ae46-66115fac906a",
   "metadata": {},
   "source": [
    "Train/Test split ensures that the model does not overfit on the data and that the model is broadly applicable to the survey. Other additions:\n",
    "* Stratify the data. This ensures that there is the same distribution of happy and unhappy customers in the training and test splits.\n",
    "* Scaling the data. This is necessary since we are using logistic regression models, which assume or prefer that the data is in a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07a6ce-c4b3-4f6e-abdf-e22db765d034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615f5a4-5b9c-42a9-a57a-c4c39046611e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "print(f'''X_train shape: {X_train.shape}\n",
    "X_test shape:  {X_test.shape}\n",
    "y_train shape: {y_train.shape}\n",
    "y_test shape:  {y_test.shape}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55f394-dc8e-487c-b0d1-3925e84ea5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8beba41-ae89-41d7-80b2-7e9e24555b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save X_train, X_test, etc. to separate .csv\n",
    "# so that we can use the same splits in different environments\n",
    "\n",
    "doc_list = [X_train, X_test, y_train, y_test]\n",
    "doc_names = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "\n",
    "for i, doc in enumerate(doc_list):\n",
    "    pd.DataFrame(doc).to_csv(f'../data/1_{doc_names[i]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878828ea-d0fd-4287-b357-d408340bbd67",
   "metadata": {},
   "source": [
    "Let's try all three scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdcc4b-f823-45e7-81f8-36505492a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Standard scaler\n",
    "# \n",
    "\n",
    "# instantiate scaler\n",
    "ss=StandardScaler()\n",
    "\n",
    "# fit scaler to X_train data\n",
    "ss=ss.fit(X_train)\n",
    "\n",
    "# transform X_train and X_test data with fitted scaler\n",
    "X_train_ss=ss.transform(X_train)\n",
    "X_test_ss=ss.transform(X_test)\n",
    "\n",
    "col_names=df.drop(['y'],axis=1).columns\n",
    "X_train_ss_df = pd.DataFrame(X_train_ss, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561f4ab-aa91-4750-a89b-cfa332de1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# MinMax scaler\n",
    "# \n",
    "\n",
    "# instantiate scaler\n",
    "mm=MinMaxScaler()\n",
    "\n",
    "# fit scaler to X_train data\n",
    "mm=mm.fit(X_train)\n",
    "\n",
    "# transform X_train and X_test data with fitted scaler\n",
    "X_train_mm=mm.transform(X_train)\n",
    "X_test_mm=mm.transform(X_test)\n",
    "\n",
    "\n",
    "col_names=df.drop(['y'],axis=1).columns\n",
    "X_train_mm_df = pd.DataFrame(X_train_mm, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e2436-ffe1-4d87-82b6-83aa5ab9960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Robust scaler\n",
    "# \n",
    "\n",
    "# instantiate scaler\n",
    "rs=RobustScaler()\n",
    "\n",
    "# fit scaler to X_train data\n",
    "rs=rs.fit(X_train)\n",
    "\n",
    "# transform X_train and X_test data with fitted scaler\n",
    "X_train_rs=rs.transform(X_train)\n",
    "X_test_rs=rs.transform(X_test)\n",
    "\n",
    "col_names=df.drop(['y'],axis=1).columns\n",
    "X_train_rs_df = pd.DataFrame(X_train_rs, columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f54c4e-f051-4856-8a29-7bb9f9151b15",
   "metadata": {},
   "source": [
    "Visualize the scalers' effect on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52bc82c-e250-4b65-ab8b-cd47e99875ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df.drop(['y'],axis=1).columns\n",
    "plot_num = 1\n",
    "\n",
    "plt.subplots(6,4, figsize=(20,50))\n",
    "\n",
    "for col in col_names:\n",
    "    \n",
    "    # colors chosen to be intepretable by different color blindness\n",
    "    \n",
    "    plt.subplot(6,4,plot_num)\n",
    "    sns.histplot(df[col], color=\"orange\", alpha=0.5).set_title('Unscaled')\n",
    "    \n",
    "    plot_num +=1\n",
    "    \n",
    "    plt.subplot(6,4,plot_num)\n",
    "    sns.histplot(X_train_ss_df[col], color=\"royalblue\").set_title('Standard scaler')\n",
    "    \n",
    "    plot_num +=1\n",
    "    \n",
    "    plt.subplot(6,4,plot_num)\n",
    "    sns.histplot(X_train_mm_df[col], color=\"gray\").set_title('MinMax scaler')\n",
    "    \n",
    "    plot_num +=1\n",
    "    \n",
    "    plt.subplot(6,4,plot_num)\n",
    "    sns.histplot(X_train_rs_df[col], color=\"pink\").set_title('Robust scaler')\n",
    "    \n",
    "    plot_num +=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a1ba2-f06e-424a-b6c7-20723a52dc31",
   "metadata": {},
   "source": [
    "Fitting the scaled data to logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b681baa-65ac-4fd0-82e6-a754dae4da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Standard Scaler\n",
    "# \n",
    "\n",
    "lm=LogisticRegression()\n",
    "\n",
    "# fit model on scaled data\n",
    "logreg_ss=lm.fit(X_train_ss,y_train)\n",
    "\n",
    "# train accuracy\n",
    "logreg_ss_train_acc=logreg_ss.score(X_train_ss,y_train)\n",
    "# test accuracy\n",
    "logreg_ss_test_acc=logreg_ss.score(X_test_ss,y_test)\n",
    "\n",
    "print(\"Standard Scaler data:\")\n",
    "print(f\"Training accuracy: {logreg_ss_train_acc}\")\n",
    "print(f\"Test accuracy: {logreg_ss_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ec2af-5d9a-4045-9766-a3d857808e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# MinMax Scaler\n",
    "# \n",
    "\n",
    "lm=LogisticRegression()\n",
    "\n",
    "# fit model on scaled data\n",
    "logreg = lm.fit(X_train_mm, y_train)\n",
    "# train accuracy\n",
    "logreg_mm_train_acc = logreg.score(X_train_mm, y_train)\n",
    "# test accuracy\n",
    "logreg_mm_test_acc = logreg.score(X_test_mm, y_test)\n",
    "\n",
    "print(\"MinMax Scaler data:\")\n",
    "print(f\"Training accuracy: {logreg_mm_train_acc}\")\n",
    "print(f\"Test accuracy: {logreg_mm_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a73ad-d25f-472b-9ede-bbbb44ac0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Robust Scaler\n",
    "# \n",
    "\n",
    "lm=LogisticRegression()\n",
    "\n",
    "# fit model on scaled data\n",
    "logreg = lm.fit(X_train_rs, y_train)\n",
    "# train accuracy\n",
    "logreg_rs_train_acc = logreg.score(X_train_rs, y_train)\n",
    "# test accuracy\n",
    "logreg_rs_test_acc = logreg.score(X_test_rs, y_test)\n",
    "\n",
    "print(\"MinMax Scaler data:\")\n",
    "print(f\"Training accuracy: {logreg_rs_train_acc}\")\n",
    "print(f\"Test accuracy: {logreg_rs_test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502e0a2-eb2d-4226-a929-3cff14918a78",
   "metadata": {},
   "source": [
    "### Next Attempt: Using Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5aa9c-d937-45d3-891c-bf0aaec5bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a13da-34c7-469f-b517-3ba9c73c5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "decision_tree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c64123-0c20-4631-9583-d608e0a954fe",
   "metadata": {},
   "source": [
    "Note: decision trees are not sensitive to scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccfcce-42b2-4d7d-a6b5-4b2d7ad51416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on unscaled data\n",
    "dtc = decision_tree.fit(X_train, y_train)\n",
    "# train accuracy\n",
    "dtc_unsc_train_acc = dtc.score(X_train, y_train)\n",
    "# test accuracy\n",
    "dtc_unsc_test_acc = dtc.score(X_test, y_test)\n",
    "\n",
    "print(\"Unscaled data:\")\n",
    "print(f\"Training accuracy: {dtc_unsc_train_acc}\")\n",
    "print(f\"Test accuracy: {dtc_unsc_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cffb8-d378-4007-8f3b-d86a9057e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on scaled data\n",
    "dtc = decision_tree.fit(X_train_ss, y_train)\n",
    "# train accuracy\n",
    "dtc_ss_train_acc = dtc.score(X_train_ss, y_train)\n",
    "# test accuracy\n",
    "dtc_ss_test_acc = dtc.score(X_test_ss, y_test)\n",
    "\n",
    "print(\"Standard Scaler data:\")\n",
    "print(f\"Training accuracy: {dtc_ss_train_acc}\")\n",
    "print(f\"Test accuracy: {dtc_ss_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e177b6-d12e-41db-92ac-74a45e2ace17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on scaled data\n",
    "dtc = decision_tree.fit(X_train_mm, y_train)\n",
    "# train accuracy\n",
    "dtc_mm_train_acc = dtc.score(X_train_mm, y_train)\n",
    "# test accuracy\n",
    "dtc_mm_test_acc = dtc.score(X_test_mm, y_test)\n",
    "\n",
    "print(\"MinMax Scaler data\")\n",
    "print(f\"Training accuracy: {dtc_mm_train_acc}\")\n",
    "print(f\"Test accuracy: {dtc_mm_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45675095-aaf7-439b-a6a8-d468628a87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on scaled data\n",
    "dtc = decision_tree.fit(X_train_rs, y_train)\n",
    "# train accuracy\n",
    "dtc_rs_train_acc = dtc.score(X_train_rs, y_train)\n",
    "# test accuracy\n",
    "dtc_rs_test_acc = dtc.score(X_test_rs, y_test)\n",
    "\n",
    "print(\"Robust Scaler data:\")\n",
    "print(f\"Training accuracy: {dtc_rs_train_acc}\")\n",
    "print(f\"Test accuracy: {dtc_rs_test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b5e7f-c304-4d3b-aa31-15ca6391794d",
   "metadata": {},
   "source": [
    "### Next attempt: Using Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62d885-5bbc-46db-be51-2cf8adf75f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b240c7-e6cc-4781-9e18-36912d257271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfm=RandomForestClassifier()\n",
    "\n",
    "# rfm.fit(X_train,y_train)\n",
    "\n",
    "# plot_decision_regions(X_train,y_train,clf=rfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47458924-359c-4477-808c-ccddc21b3ad1",
   "metadata": {},
   "source": [
    "### Next attempt: Implementing K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618c615-f197-410f-89b9-b0e499c35220",
   "metadata": {},
   "source": [
    "This allows for averaging out of any variations on where the train/test splits are taken from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440ae1b-5715-4c21-9436-e23f927809fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f1a44-1a34-4bbb-9cfd-609e3c71bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaving some in reserve for a test set\n",
    "# splitting out 20% for test set\n",
    "X_remainder, X_test, y_remainder, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b19be2-8a3a-4af8-a518-6f549f84986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# 1. Instanitate model\n",
    "logit = LogisticRegression(random_state=1)\n",
    "\n",
    "# 2. Fit model on 5 folds.\n",
    "# The variable \"scores\" will hold 5 accuracy scores, \n",
    "# each from a different train and validation split\n",
    "scores = cross_val_score(logit, X_remainder, y_remainder, cv = 5,n_jobs=8)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34bc4c-be04-410e-85e1-0063b4828770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the results\n",
    "cross_validation_scores = []\n",
    "\n",
    "C_range = np.logspace(-6,6,13)\n",
    "\n",
    "#Do some cross validation\n",
    "for c in C_range:\n",
    "    lr_model = LogisticRegression(C=c,random_state=1)\n",
    "    \n",
    "    # the cross validation score (mean of scores from all folds)\n",
    "    cv_score = np.mean(cross_val_score(lr_model, X_remainder, y_remainder, cv = 5))\n",
    "    \n",
    "    cross_validation_scores.append(cv_score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C_range, cross_validation_scores,label=\"Cross Validation Score\",marker='.')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('Regularization Parameter: C')\n",
    "plt.ylabel('Cross Validation Score')\n",
    "plt.grid()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067a226-ffbb-4b5a-8fe5-ed393a6df96d",
   "metadata": {},
   "source": [
    "### Next Attempt: Implement PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4288d-7d67-4adc-a9e6-ac414cfd7beb",
   "metadata": {},
   "source": [
    "PCA, or principal component analysis, will help reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d498c93-ff6e-47d6-989a-89f5713a2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3d580-b6d1-49d7-ad74-97d15e9db0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate & fit PCA model to the breast cancer data\n",
    "# Default n_components will generate the same number of PCs as you have features \n",
    "my_PCA = PCA()\n",
    "my_PCA.fit(X_train)\n",
    "\n",
    "# transform data \n",
    "X_train_PCA = my_PCA.transform(X_train)\n",
    "X_test_PCA = my_PCA.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb70a6-8301-484a-98c3-5f62302fbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Variance captured by PC1: {my_PCA.explained_variance_[0]: 0.3f}\")\n",
    "print(f\"Variance captured by PC2: {my_PCA.explained_variance_[1]: 0.3f}\")\n",
    "\n",
    "print(f\"Proportion of variance captured by PC1: {my_PCA.explained_variance_ratio_[0]: 0.3f}\")\n",
    "print(f\"Proportion of variance captured by PC2: {my_PCA.explained_variance_ratio_[1]: 0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb8e49-2a1e-413c-bf1b-2abdd0e0e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_PCA.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73979ea-bd00-491e-9231-02cbae04807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_var = my_PCA.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0a008-1fae-4840-98c5-9f532102195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,7),expl_var,marker='.')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.xticks(range(1,8,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f9bc1-bb9e-4a9d-80a8-7254779f3290",
   "metadata": {},
   "source": [
    "The problem is that we're working with a limited dataset, so we don't have the luxury of paring it down much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402031eb-9d11-4a01-8a4c-4dfe31c02fd7",
   "metadata": {},
   "source": [
    "That being said, it looks like at 3 principal components is where the line makes the 'elbow', so we'll use `n_components=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d66c25-033d-4caa-8ea3-244c3b7742eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit\n",
    "my_PCA = PCA(n_components = 3)\n",
    "my_PCA.fit(X_train)\n",
    "\n",
    "# Transform train and test\n",
    "X_train_PCA = my_PCA.transform(X_train)\n",
    "X_test_PCA = my_PCA.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee63f85-2d5f-4241-aec9-ffdbb780b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original: {X_train.shape}')\n",
    "print(f'PCA Transformed: {X_train_PCA.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ab8e7-c1fd-4c5e-86ba-9e2b6afb49a4",
   "metadata": {},
   "source": [
    "Alternatively using PCA to capture 90% of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a4a232-49a4-4d06-b63c-ad37b048ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit\n",
    "my_PCA = PCA(n_components = .9)\n",
    "my_PCA.fit(X_train)\n",
    "\n",
    "# Transform train and test\n",
    "X_train_PCA = my_PCA.transform(X_train)\n",
    "X_test_PCA = my_PCA.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a96a6b-13e9-443b-98fd-26d3f1b00ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original: {X_train.shape}')\n",
    "print(f'PCA Transformed: {X_train_PCA.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d29e0-12fd-4b0b-9bba-eb932409c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_PCA.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891a66e-fb45-4bee-b6b8-7871c75c0c2a",
   "metadata": {},
   "source": [
    "Using the 90% determination, PCA drops only one of the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad416f-7eb3-4c08-a571-71c343d386b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_PCA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24708798-6d86-42e5-a15a-63ec83b3c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# Create a heatmap. The values are all contained in the .components_ attribute\n",
    "ax = sns.heatmap(my_PCA.components_,\n",
    "                 cmap='coolwarm',\n",
    "                 yticklabels=[ \"PC\"+str(x) for x in range(1,my_PCA.n_components_+1)],\n",
    "                 xticklabels=list(df[[col for col in df.columns if col != 'y']].columns),\n",
    "                 linewidths = 1,\n",
    "                 annot = True,\n",
    "                 vmin=-1,\n",
    "                 vmax=1,\n",
    "                 cbar_kws={\"orientation\": \"vertical\"})\n",
    "\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=25)\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d24a6-6756-46de-84e1-a24729b74939",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_PCA.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c5736-6a1a-4751-aaef-0f0c18b31ed8",
   "metadata": {},
   "source": [
    "From the heatmap, we see that:\n",
    "* PC1 is moderately negatively correlated with `complete` and `courier`\n",
    "* PC2 is very strongly correlated with `contents`\n",
    "* PC3 is moderately negatively correlated with `price` while being moderately positively correlated with `courier`\n",
    "* PC4 is moderately negatively correlated with `time` and `app` but moderately positively correlated with `complete`\n",
    "* PC5 is moderately positively correlated with `complete` while being moderately negatively correlated with `price` and `courier`\n",
    "\n",
    "The explained variance ratio shows that the first two principal components explain 32.9% + 24.4% or 57.3% of the data. There is much that is not being captured by those first two principal components, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e04777-060b-4d59-a8bc-f84229c426a7",
   "metadata": {},
   "source": [
    "When we plot the first two principal components, we see that it's a wash. PCA doesn't appear to be that helpful in training a model with higher-than-73% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91896ab-005f-4925-8e97-313ed8494def",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "scatter = plt.scatter(X_train_PCA[:,0], X_train_PCA[:,1], c=y_train, cmap='tab10')\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "\n",
    "# Generate Legend\n",
    "classes = [\"0...'I'm not sure\", \"1...if this's right\"]\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606e60a-8c67-44b3-a07d-fce298e270df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# We need to scale the data since tSNE is also distance based\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "my_tSNE = TSNE(n_components=2)\n",
    "\n",
    "X_tSNE = my_tSNE.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a64204-49b6-4bd8-886f-45d44efc83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the tSNE-transformed data (only the first two dimensions)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X_tSNE[:,0],X_tSNE[:,1],c=y)\n",
    "\n",
    "plt.xlabel(\"tSNE Component 1\")\n",
    "plt.ylabel(\"tSNE Component 2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d522a4-e69f-4e1b-8df2-ed5188dd2023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bd54c-959f-4e8f-82b3-93711cdb4788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace176f0-ca7c-4386-8a88-6af225971836",
   "metadata": {},
   "source": [
    "Comparing default logreg to PCA'd logreg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af54574-ad4a-457e-8ed0-676de5908eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use all the default parameters for now\n",
    "my_logreg = LogisticRegression()\n",
    "\n",
    "# Fitting to original data\n",
    "my_logreg.fit(X_train,y_train)\n",
    "\n",
    "# Scoring on original train and test sets\n",
    "print(f'Train Score: {my_logreg.score(X_train, y_train)}')\n",
    "print(f'Test Score: {my_logreg.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d02b5e-1b80-405c-85bf-0f2ee0564e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same but fit on the PCA transformed data\n",
    "my_logreg_PCA = LogisticRegression()\n",
    "\n",
    "# Fitting to PCA data\n",
    "my_logreg_PCA.fit(X_train_PCA,y_train)\n",
    "\n",
    "# Scoring on PCA train and test sets\n",
    "print(f'Train Score: {my_logreg_PCA.score(X_train_PCA, y_train)}')\n",
    "print(f'Test Score: {my_logreg_PCA.score(X_test_PCA, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58dbf58-519d-4c91-8c41-0d07da7462ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af6f45-2eb7-4843-a5bc-43bde7879f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b0360-4987-4138-b1c0-afec27802896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df443bc6-5f4f-4a05-8205-1d6500d033fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f3cc5-726e-4c60-a0fb-66e4b1ddb29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6126ad-f154-47d2-aee5-dde017b0dad6",
   "metadata": {},
   "source": [
    "### Next attempt: Using a Pipeline and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d5971-99eb-44f7-8b68-e565683858ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8146e-173f-45a7-b030-8d504acfcc5b",
   "metadata": {},
   "source": [
    "I commented out the code to run the grid search so that we don't unnecessarily run it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281ab17-7b41-4c51-ac53-42ef865e5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('normalize',None),\n",
    "              ('pca',None),\n",
    "              ('model', None)]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [{\"model\":[LogisticRegression(penalty=\"l2\",max_iter=1000),\n",
    "                        LogisticRegression(penalty=\"l1\",solver=\"liblinear\",max_iter=1000)],\n",
    "               \"pca\":[\"passthrough\",PCA()] + list(PCA(n_components=i) for i in range(1,7)),\n",
    "               \"normalize\":[MinMaxScaler(),StandardScaler(),\"passthrough\"],\n",
    "               \"model__C\":np.logspace(-4,4,5)},\n",
    "              {\"model\":[SVC(kernel=\"poly\"),SVC(kernel=\"rbf\")],\n",
    "               \"pca\":[\"passthrough\",PCA()] + list(PCA(n_components=i) for i in range(1,7)),\n",
    "               \"normalize\":[MinMaxScaler(),StandardScaler(),\"passthrough\"],\n",
    "               \"model__C\":np.logspace(-4,4,5),\n",
    "               \"model__gamma\":np.linspace(0.01,10.0,5)}]\n",
    "              \n",
    "    \n",
    "# grid = GridSearchCV(pipe, param_grid, cv=5,verbose=3,n_jobs=-1,scoring=\"f1_weighted\")\n",
    "# fittedgrid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57cb231-418c-49fd-8278-df9871e20a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best estimator object\n",
    "# fittedgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e3c0d-0f65-4bae-8b44-485642d7d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean test score for each CV fold\n",
    "# fittedgrid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bc3ee-c7e2-4edd-8ef2-15f4dd0d0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results=pd.DataFrame([fittedgrid.cv_results_])\n",
    "# cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7347b20-526a-4cb6-a7bc-021e439c8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "# fittedgrid.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf3f77-649a-431d-954f-73db33a0d254",
   "metadata": {},
   "source": [
    "fittedgrid.score = 0.6842634489693313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7406f23-ce48-46b0-9d6f-b2ffb55327ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters\n",
    "# fittedgrid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3879f-733f-4689-a51f-e05060518d4e",
   "metadata": {},
   "source": [
    "```python\n",
    "{'model': SVC(gamma=10.0),\n",
    " 'model__C': 1.0,\n",
    " 'model__gamma': 10.0,\n",
    " 'normalize': MinMaxScaler(),\n",
    " 'pca': PCA(n_components=4)}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d5437b-4ef3-48f7-acaa-c65f19f866f2",
   "metadata": {},
   "source": [
    "Ok, so we now have our best result, but it's  still under 70% accuracy. Let's explore the hyperparameter space around this best result more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ff695-e65e-40c1-a2d1-e76ec45c19dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators = [('normalize',None),\n",
    "              ('pca',None),\n",
    "              ('model', None)]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [{\"model\":[SVC(kernel=\"poly\"),SVC(kernel=\"rbf\")],\n",
    "               \"pca\":[PCA(n_components=4)],\n",
    "               \"normalize\":[MinMaxScaler()],\n",
    "               \"model__C\":np.logspace(-0,2,5),\n",
    "               \"model__gamma\":np.linspace(5,50.0,5)}]\n",
    "              \n",
    "    \n",
    "# grid = GridSearchCV(pipe, param_grid, cv=5,verbose=2,n_jobs=-1,scoring=\"f1_weighted\")\n",
    "# fittedgrid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb539b-7994-4f35-8e32-15f2ed5a4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters\n",
    "# fittedgrid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d568e8-f94d-41ef-a310-766e04670f64",
   "metadata": {},
   "source": [
    "```python\n",
    "{'model': SVC(gamma=5.0),\n",
    " 'model__C': 1.0,\n",
    " 'model__gamma': 5.0,\n",
    " 'normalize': MinMaxScaler(),\n",
    " 'pca': PCA(n_components=4)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3bfa9f-1187-4fee-abac-5a42030c834a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# score\n",
    "# fittedgrid.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b067af-e48e-48d4-84c0-bcfad8fff8cd",
   "metadata": {},
   "source": [
    "fittedgrid.score=0.72776346460557"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7fd09-df68-46fb-872a-000decafb9f6",
   "metadata": {},
   "source": [
    "That's almost over 73%! Let's try one more round of grid searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1218828f-19d1-46c1-805b-20c604afd334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators = [('normalize',None),\n",
    "              ('pca',None),\n",
    "              ('model', None)]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [{\"model\":[SVC(kernel=\"poly\")],\n",
    "               \"pca\":[PCA(n_components=4)],\n",
    "               \"normalize\":[MinMaxScaler()],\n",
    "               \"model__C\":np.linspace(0.5,1.5,10),\n",
    "               \"model__gamma\":np.linspace(0,10.0,10)}]\n",
    "              \n",
    "    \n",
    "# grid = GridSearchCV(pipe, param_grid, cv=5,verbose=2,n_jobs=-1,scoring=\"f1_weighted\")\n",
    "# fittedgrid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058bf27d-3939-4d96-a58e-79d08683bed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best hyperparameters\n",
    "# fittedgrid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09c270b-785d-4fbf-92be-d60d550f360a",
   "metadata": {},
   "source": [
    "```python\n",
    "{'model': SVC(C=0.8333333333333333, gamma=3.3333333333333335, kernel='poly'),\n",
    " 'model__C': 0.8333333333333333,\n",
    " 'model__gamma': 3.3333333333333335,\n",
    " 'normalize': MinMaxScaler(),\n",
    " 'pca': PCA(n_components=4)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6bdca-25fb-40f4-8742-d63f8472069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "# fittedgrid.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78beda-f681-4a44-a352-075f2f6bb89c",
   "metadata": {},
   "source": [
    "fittedgrid.score=0.5886752136752137"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd11690-0583-406a-b56b-1e6583f66ad4",
   "metadata": {},
   "source": [
    "Ok, so that was worse than last time. I think we're done grid searching. Maybe the results of the [statistical modeling](#statistical_modeling) will give us more insight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d7a4a-557a-4713-a44d-5e14ba898367",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "best_params={'model': SVC(gamma=5.0),\n",
    " 'model__C': 1.0,\n",
    " 'model__gamma': 5.0,\n",
    " 'normalize': MinMaxScaler(),\n",
    " 'pca': PCA(n_components=4)}\n",
    "best_params\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cd236-69df-479b-95ae-3c2074ec212f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039dee78-d58b-4e1e-880d-4048f1aa690d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965fdf1d-216c-4f04-9373-85d5e383bce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c27b7a8a-3dfd-4b2c-9115-64adda8ddb02",
   "metadata": {},
   "source": [
    "### Basic Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279da7a0-bce7-417e-beff-649065cfc07d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate model \n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# score on the training data \n",
    "print(logreg.score(X_train, y_train))\n",
    "\n",
    "# score on the testing data\n",
    "print(logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79168818-46c7-4a6b-a410-9f0369968dbd",
   "metadata": {},
   "source": [
    "Ok, that's an improvement. Let's keep going!  \n",
    "\n",
    "It is interesting to note that the accuracy is higher for the testing set - usually it's the other way around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679a99d-60e9-486a-b1e2-4da93a066366",
   "metadata": {},
   "source": [
    "### Third attempt: Using Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d3b77-937a-4828-9f70-b29f0d107ce4",
   "metadata": {},
   "source": [
    "This allows for control on how the model learns based on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188288e6-b052-449a-bdfe-a526b013fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75b3c1-ea44-4c3e-9d13-a38d2003888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(model_prediction.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25baec27-14d3-4fe3-9b39-bed4391ce06f",
   "metadata": {},
   "source": [
    "L2 (Square function): adds greater penalties for large coefficients, but a smaller penalty for coefficients close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e26d56-217f-496f-94d6-71592b14f39f",
   "metadata": {},
   "source": [
    "L1 (Absolute value function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead99e0-ab68-41be-9db0-bf270114ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in [1E-3,0.1,0.50,1.0,5,10,100,1000,1E10]:\n",
    "    lr = LogisticRegression(penalty=\"l2\",C=weight,max_iter=10000)\n",
    "    lr.fit(X_train,y_train)\n",
    "    train_acc = lr.score(X_train,y_train)\n",
    "    test_acc = lr.score(X_test,y_test)\n",
    "    print(\"L2 Weight={} train_acc={:4.3f} test_acc={:4.3f}\".format(weight,train_acc,test_acc))\n",
    "print(\"*\"*80)\n",
    "for weight in [1E-3,0.1,0.50,1.0,5,10,100,1000,1E10]:\n",
    "    lr = LogisticRegression(penalty=\"l1\",solver=\"liblinear\",C=weight,max_iter=10000)\n",
    "    lr.fit(X_train,y_train)\n",
    "    train_acc = lr.score(X_train,y_train)\n",
    "    test_acc = lr.score(X_test,y_test)\n",
    "    print(\"L1 Weight={} train_acc={:4.3f} test_acc={:4.3f}\".format(weight,train_acc,test_acc))\n",
    "    coefs = list(\"{:4.3f}\".format(c) for c in lr.coef_[0])\n",
    "    print(\"     L2 coefs\",\" \".join(coefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee0a58-a9ce-4944-83f6-5046e0d9d8b0",
   "metadata": {},
   "source": [
    "### Fourth Attempt: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f75b1c-96cf-4eac-88d0-6096c6290d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(model_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593da31-031d-4835-940c-f33f147d0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# # plot the predictions\n",
    "# plt.scatter(X, model_prediction, c='blue', label=\"predictions\") \n",
    "# # plot original data (with the y-values offset a tiny bit to reduce overlap)\n",
    "# plt.scatter(X, y+0.1, c ='red', label=\"data\")\n",
    "# plt.legend()\n",
    "# plt.xlabel('X value')\n",
    "# plt.ylabel('class label (0 or 1)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba4bf6-d028-4c78-8ee1-7093d3c7070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnames = linear_regression_model.feature_names_in_\n",
    "# coef = linear_regression_model.coef_\n",
    "# output = list(zip(fnames,coef))\n",
    "# print(\"\\n\".join(list(\"{:12}= {:5.3f}\".format(*t) for t in output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e6fb08-5cf8-4f75-bb72-a11dd87fedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_regression_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ca645-840c-4047-8db3-9b274ac93ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_regression_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c0543-230d-4faf-8655-42c8f3231708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cffa9-2425-49ac-99f7-19e39e82290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to visulalize the decision boundaries\n",
    "# from BrainStation\n",
    "def PlotBoundaries(model, X, Y, plotsize=(6,4)) :\n",
    "    '''\n",
    "    Helper function that plots the decision boundaries of a model and data (X,Y)\n",
    "    code modified from: https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html\n",
    "    '''\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1,X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=plotsize)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "    #Plot\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y,s=20, edgecolor='k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5272ca-aa71-41b1-9373-71d4ccffc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup X and y\n",
    "X=df[[col for col in df.columns if col != 'y']].copy()\n",
    "y=df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f83db-72ad-4de8-b6a1-dc86ac9f2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "# # Instantiate the model & fit it to our data\n",
    "# KNN_model = KNeighborsClassifier(n_neighbors=3)#,metric=\"cosine\")\n",
    "# KNN_model.fit(X_train, y_train)\n",
    "\n",
    "# # Score the model on the test set\n",
    "# test_predictions = KNN_model.predict(X_test)\n",
    "# test_accuracy = accuracy_score(test_predictions, y_test)\n",
    "# print(f\"Test set accuracy: {test_accuracy}\")\n",
    "\n",
    "# # PlotBoundaries(KNN_model, X, y, plotsize=(10,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95b5e7-1f83-4bb6-bea7-52ce0fffe437",
   "metadata": {},
   "source": [
    "### `LazyPredict`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc35f1a-3ffc-429b-8f61-bba9a63976c4",
   "metadata": {},
   "source": [
    "`LazyPredict` offers a way to test the accuracy of many ML models in their basic configuration to see which performs the best on the target dataset. It helps in the exploration and experimentation phase by searching for the best model for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a31725-f3d1-4cc5-9d6e-28d6f8fce639",
   "metadata": {},
   "source": [
    "In order to use this, I will switch environments to `lazypredict`, a dedicated environment for this package, as I was encountering errors when running it within my `sklearn` environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae034308-e90b-449f-a6b7-3b85c8c54561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb045f-5394-42d9-9786-2d492b8ecccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import X_train, X_test, etc.\n",
    "\n",
    "X_train=pd.read_csv('../data/1_X_train.csv').to_numpy()\n",
    "X_test=pd.read_csv('../data/1_X_test.csv').to_numpy()\n",
    "y_train=pd.read_csv('../data/1_y_train.csv').to_numpy().flatten()\n",
    "y_test=pd.read_csv('../data/1_y_test.csv').to_numpy().flatten()\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40533d4c-6dff-415c-b1c5-d256638d80d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94954356-6519-4f69-8a16-0f1b9c94894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5300dea1-130f-43dd-90be-48f2fa105971",
   "metadata": {},
   "source": [
    "`LGBMClassifier` gave the best results. I will now explore the hyperparameter space within this package to try to push the accuracy above 73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fada329-b7bb-469e-99b7-87ae070a84a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82cc3bbc-6746-40cb-9752-7def0a9b7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('../data/1_X_train.csv').to_numpy()\n",
    "X_test=pd.read_csv('../data/1_X_test.csv').to_numpy()\n",
    "y_train=pd.read_csv('../data/1_y_train.csv').to_numpy().flatten()\n",
    "y_test=pd.read_csv('../data/1_y_test.csv').to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5503db-c005-49b0-b4d7-4c9df420141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293442ad-3200-4eb5-8366-e847a5f06860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the LGBMClassifier model\n",
    "# model = lgb.LGBMClassifier()\n",
    "\n",
    "# # define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'num_leaves': list(np.round(np.linspace(start=2,stop=101,num=5)).astype(int)),\n",
    "#     'learning_rate': list(np.logspace(start=-3,stop=3,num=5)),\n",
    "#     'n_estimators': [50, 200],\n",
    "#     'max_depth': [-1, 10, 20]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de1a90b-bd56-490a-a311-92be707f8b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create the GridSearchCV object\n",
    "# grid_search = GridSearchCV(estimator=model, \n",
    "#                            param_grid=param_grid, \n",
    "#                            cv=5, \n",
    "#                            scoring='accuracy', \n",
    "#                            verbose=2,\n",
    "#                            n_jobs=-1)\n",
    "\n",
    "# # perform the grid search\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b275ccc-f67e-435b-840b-56ed968d5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LGBMClassifier model\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "# define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': list(np.round(np.linspace(start=2,stop=101,num=2)).astype(int)),\n",
    "    'learning_rate': list(np.logspace(start=-3,stop=3,num=2)),\n",
    "    'n_estimators': [50],#, 200],\n",
    "    'max_depth': [-1]#, 10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cd8b4d-a5f9-42e6-96a5-6604e1379ff8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[LightGBM] [Info] Number of positive: 44, number of negative: 36\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31\n",
      "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550000 -> initscore=0.200671\n",
      "[LightGBM] [Info] Start training from score 0.200671\n",
      "[CV] END learning_rate=0.001, max_depth=-1, n_estimators=50, num_leaves=2; total time=   0.1s\n",
      "[LightGBM] [Info] Number of positive: 44, number of negative: 36\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31\n",
      "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550000 -> initscore=0.200671\n",
      "[LightGBM] [Info] Start training from score 0.200671\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[CV] END learning_rate=1000.0, max_depth=-1, n_estimators=50, num_leaves=2; total time=   0.0s\n",
      "[LightGBM] [Info] Number of positive: 44, number of negative: 36\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31\n",
      "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550000 -> initscore=0.200671\n",
      "[LightGBM] [Info] Start training from score 0.200671\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 55, number of negative: 45\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31\n",
      "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550000 -> initscore=0.200671\n",
      "[LightGBM] [Info] Start training from score 0.200671\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.001, 1000.0], &#x27;max_depth&#x27;: [-1],\n",
       "                         &#x27;n_estimators&#x27;: [50], &#x27;num_leaves&#x27;: [2, 101]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.001, 1000.0], &#x27;max_depth&#x27;: [-1],\n",
       "                         &#x27;n_estimators&#x27;: [50], &#x27;num_leaves&#x27;: [2, 101]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.001, 1000.0], 'max_depth': [-1],\n",
       "                         'n_estimators': [50], 'num_leaves': [2, 101]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           scoring='accuracy', \n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# perform the grid search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eaf4b43-46fa-4573-950a-ded548b26001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 1000.0, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 2}\n",
      "Best Cross-Validation Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "# get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Cross-Validation Accuracy: {best_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a1b61-fc3b-4dd3-b935-27901b4d3d34",
   "metadata": {},
   "source": [
    "Save in joblib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c57e05f2-d21d-4cb3-b818-0d3952935fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1584a772-1c60-4035-b671-6f08b57f698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../joblib/1_lgbmclassifier_20240517']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the grid search results to a file\n",
    "joblib.dump(grid_search, '../joblib/1_lgbmclassifier_20240517')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a7411d8-e3c7-4678-a4a7-36e40db0ecdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the grid search results from the file (for demonstration purposes)\n",
    "loaded_grid_search = joblib.load('../joblib/1_lgbmclassifier_20240517')\n",
    "\n",
    "# make predictions using the best model from the loaded grid search results\n",
    "best_model = loaded_grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66a373e5-fe5b-47a4-8915-f53d0646aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9322955f-a97b-40dc-9c6a-c8bb962b82c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 55, number of negative: 45\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31\n",
      "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550000 -> initscore=0.200671\n",
      "[LightGBM] [Info] Start training from score 0.200671\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=lgb.LGBMClassifier(learning_rate=1000,\n",
    "                   max_depth=-1,\n",
    "                   n_estimators=50,\n",
    "                   num_leaves=2)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# checking to see what the score is on the training dataset\n",
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "281a15d2-0de6-4c4c-86a7-f8687b6362e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score on test set\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97793105-9220-4420-aaa8-21b12414b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4a9aa-5961-4a96-95e3-d726d52ccd07",
   "metadata": {},
   "source": [
    "Load in joblib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af337a1f-23bb-4d5f-ae97-b514b26ef10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models=joblib.load(filename='./joblib/lazypredict_01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600a54c-663f-4282-9b33-d6d9b70743f1",
   "metadata": {},
   "source": [
    "## Statistical Modeling <a name=\"statistical_modeling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23089a91-617c-4ab9-8364-4cd49f313154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06fcda9-ef8d-4601-92c2-41d70a349953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add constant to our X\n",
    "X_const=sm.add_constant(df[[col for col in df.columns if col != 'y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c2f5d-c01f-414a-97b4-1c70bc9f19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it out\n",
    "X_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb15d7b-6e3e-4855-a129-2cd688adfa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the logistic regression model \n",
    "logreg = sm.Logit(y, X_const)\n",
    "\n",
    "# fit the model\n",
    "logreg_results = logreg.fit()\n",
    "\n",
    "# display the results \n",
    "logreg_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3dcaff-761c-414d-a1ae-2cf156c139f7",
   "metadata": {},
   "source": [
    "All features have p-values above 0.05 except time, which is just under the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684833e-3b10-49ae-ac6e-a10ec4c58e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the model predictions as probabilities \n",
    "# and saving to 'y_proba'\n",
    "y_proba = logreg_results.predict(X_const)\n",
    "\n",
    "# view \n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101613de-be9c-40e6-9280-d778eeea1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume probability >=50%\n",
    "# is a happy customer prediction\n",
    "# so we'll make the soft preds into hard preds\n",
    "y_pred = np.where(y_proba >= 0.5, 1, 0)\n",
    "\n",
    "# look at the model's predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0f668-651f-4294-9c95-cc106d5081b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "# find where predicted = true survival\n",
    "# then divide by the number of predictions/passengers\n",
    "acc = (y_pred == y).sum()/df.shape[0]\n",
    "\n",
    "# Print the accuracy score\n",
    "print(f'Model accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2be8f-e41c-4af6-a55f-e539704cfe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put params into a dataframe\n",
    "results_df = pd.DataFrame(logreg_results.params, columns=['Coefficient'])\n",
    "\n",
    "# view the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904dfb9-2d0f-4278-9128-ad9161546d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and add the odds ratios to results_df\n",
    "# log odds is more interpretable\n",
    "results_df['odds_ratio'] = np.exp(results_df['Coefficient'])\n",
    "\n",
    "# display the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7a4f4-aadc-4ed0-ac36-149e08d1390c",
   "metadata": {},
   "source": [
    "Each component of the survey shows that it has an impact on the overall happiness of the customer. Time is the largest factor, which makes sense: when you're hungry, you want food as soon as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3081d1-9559-4461-a331-fb51ed184f20",
   "metadata": {},
   "source": [
    "Given that the p-values of time was the only factor that was below the 0.05 threshold suggests that we should try this again with only time as the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6565e5-8c41-4a08-9e6c-634d6a8a92d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add constant to our X\n",
    "X_const=sm.add_constant(df[[col for col in df.columns if col != 'y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee62fa-9779-4bba-8d87-b87cc267963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it out\n",
    "X_const=X_const.drop([col for col in X_const.columns if (col !='a_time') or (col !='const')],axis=1)\n",
    "X_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e696da2-9907-4c15-a596-8b3af7f413db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the logistic regression model \n",
    "logreg = sm.Logit(y, X_const)\n",
    "\n",
    "# fit the model\n",
    "logreg_results = logreg.fit()\n",
    "\n",
    "# display the results \n",
    "logreg_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af368050-453b-4dfc-a977-65be0e802214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the model predictions as probabilities \n",
    "# and saving to 'y_proba'\n",
    "y_proba = logreg_results.predict(X_const)\n",
    "\n",
    "# view \n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753933d-77d2-4345-b985-91e481e2e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume probability >=50%\n",
    "# is a happy customer prediction\n",
    "# so we'll make the soft preds into hard preds\n",
    "y_pred = np.where(y_proba >= 0.5, 1, 0)\n",
    "\n",
    "# look at the model's predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae1d80-bbae-437a-8865-82c4fb99441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "# find where predicted = true survival\n",
    "# then divide by the number of predictions/passengers\n",
    "acc = (y_pred == y).sum()/df.shape[0]\n",
    "\n",
    "# Print the accuracy score\n",
    "print(f'Model accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e12f0-db30-4927-89aa-b74c027944d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put params into a dataframe\n",
    "results_df = pd.DataFrame(logreg_results.params, columns=['Coefficient'])\n",
    "\n",
    "# view the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361fae91-416d-4af5-bbc8-64f8a4dd627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and add the odds ratios to results_df\n",
    "# log odds is more interpretable\n",
    "results_df['odds_ratio'] = np.exp(results_df['Coefficient'])\n",
    "\n",
    "# display the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa31bf8-9a8b-410c-806f-5202accb4572",
   "metadata": {},
   "source": [
    "Oops, that did not work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightgbm",
   "language": "python",
   "name": "lightgbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
