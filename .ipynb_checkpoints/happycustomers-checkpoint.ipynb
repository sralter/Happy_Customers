{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca989e3-6fce-48fd-b44c-bd5e261375bf",
   "metadata": {},
   "source": [
    "# Happy Customers - An Apziva Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be1ab2-763b-43a1-bd04-809d0944c0df",
   "metadata": {},
   "source": [
    "By Samuel Alter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f2033-1c74-46e3-b1c9-8fc37a257748",
   "metadata": {},
   "source": [
    "This project centers on a customer survey dataset from a delivery company. The dataset consists of the following:\n",
    "* `Y`: The target attribute, indicating whether the customer noted their happiness or unhappiness\n",
    "* `X1`: Order was delivered on time\n",
    "* `X2`: Contents of the order was as expected (think: after the order has been delivered)\n",
    "* `X3`: I ordered everything that I wanted to order (think: while placing the order)\n",
    "* `X4`: I paid a good price for my order\n",
    "* `X5`: I am satisfied with my courier\n",
    "* `X6`: The app makes ordering easy for me\n",
    "\n",
    "Attributes `X1` through `X6` are on a 1 to 5 scale, with 5 indicating most agreement with the statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f15363-93ba-468e-8ff6-73effe14adb8",
   "metadata": {},
   "source": [
    "The goals of this project are to train a model that predicts whether a customer is happy or not, based on their answers to the survey. Specifically, I am to reach 73% accuracy or higher with my modeling, or explain why my solution is superior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939dc854-a7cf-4cfc-8ed1-6fcd60fdf242",
   "metadata": {},
   "source": [
    "A stretch goal would be to determine which features are more important when predicting a customer's happiness. What is the minimal set of attributes or features that would preserve the most information about the problem, while at the same time increasing predictability? The aim here is to see if any question can be eliminated in the next survey round.\n",
    "\n",
    "The statistical analysis of the features can be found in the [Statistical Modeling](#statistical_modeling) section at the end of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b6ad4-ccaa-4cf2-b614-68c593b9c147",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadebfef-ac42-42dc-93da-86152a8f73a5",
   "metadata": {},
   "source": [
    "1. [EDA](#eda)\n",
    "> [EDA Summary](#eda_sum)\n",
    "1. [Initial `lazypredict` model exploration](#lazy_predict)\n",
    "> This is run in the `lazypredict` environment\n",
    "> * [Random seed initialization](#rand). This output is saved to a file so that it can be accessed later on in the notebook when using a different environment.\n",
    "> * [Read in and setup dataset](#read)\n",
    "> * [Run `LazyClassifier`](#lazy)\n",
    "1. [Switch to `sklearn` environment](#sklearn)\n",
    "> The sections involving ML algorithms are run in this environment\n",
    "1. `XGBoost`\n",
    "> * [Initial XGBoost model run](#xgboost_initial)\n",
    "> * [Grid search exploration with the `XGboost` algorithm](#xgboost)\n",
    "1. [`SGDClassifier`](#sgdc)\n",
    "> Grid search exploration with the `SGDClassifier` algorithm\n",
    "> * [`get_dummies`](#sgdc_dummies)\n",
    "> * [`train_test_split` on OHE'd dataset](#tts_ohe)\n",
    "> * [Pipeline with `SGDClassifier` and OHE'd data](#pipe_ohe)\n",
    "> * [Most important features of the OHE'd data](#rfe_ohe)\n",
    "> * [New pipeline with `SGDClassifier` and categorical (not OHE'd) data](#pipe_notohe)\n",
    "> * [Most important features of the non-OHE'd data](#rfe_notohe)\n",
    "> * [Last attempt at pipeline and grid search with thresholded (non-OHE'd) data](#thresholded_grid)\n",
    "> * [Most important features on the thresholded data](#rfe_threshold)\n",
    "1. [`hyperopt`](#hyper)\n",
    "> Our accuracies are still volatile and not ideal, so we will use the `hyperopt` package to help us arrive at better hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a62449-24e0-4c75-93ee-f2f4349983d8",
   "metadata": {},
   "source": [
    "## EDA <a name='eda'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a639d5-0487-4963-9b3f-da593d1d56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679289a-2006-43ae-b5dd-a5b624f13ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/1_data.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2a886-4cf9-483f-8163-646da43ab0ee",
   "metadata": {},
   "source": [
    "Let's rename the columns to make them more intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889f8a2-234c-403f-97a5-f50356cb0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "# using alphabet prefixes to ensure correct order of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc324c-a621-45da-baac-e511e2fb753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8663c88-604b-4d89-90e0-bd12ddc5d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c11873-7a31-4e05-8a62-fe3903ed9aaa",
   "metadata": {},
   "source": [
    "It seems like most of the participants in the survey were happy about the time it took to receive the order and app experience, but all of this will require more exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efb9c5-1b25-4b8b-a0bc-9660d99f8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc811c-c112-4725-b717-37beec08347a",
   "metadata": {},
   "source": [
    "### Figure 1: Distribution of target (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa1877-3f8e-4659-84ab-6904c55e53af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data labels\n",
    "x=[0,1]\n",
    "y=[df['y'].value_counts()[0],df['y'].value_counts()[1]]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax=sns.countplot(data=df, x='y',zorder=3,)\n",
    "plt.title('Distribution of Customer Happiness in Target (y)')\n",
    "plt.xlabel('Target Values\\n0: Unhappy, 1: Happy')\n",
    "plt.ylabel('Count')\n",
    "ax.yaxis.grid(True,zorder=0)\n",
    "for i in range(len(x)):\n",
    "    plt.text(i, y[i], y[i], ha = 'center')\n",
    "plt.savefig('../figs/1_ydistribution.pdf')\n",
    "plt.savefig('../figs/1_ydistribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a02ca-e9a0-4ec2-9f63-b1b0915e8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In the dataset, {round(df['y'].value_counts()[1]/df['y'].shape[0]*100,2)}% of respondents were happy,\\nwhile {round(df['y'].value_counts()[0]/df['y'].shape[0]*100,0)}% of respondents were unhappy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c56c0a-dc3d-41c1-be6d-ee942fcf0680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare X data for plotting\n",
    "col_list=[]\n",
    "\n",
    "for i in df.columns:\n",
    "    col_list.append(i)\n",
    "    \n",
    "col_list.remove('y')\n",
    "\n",
    "df_melted=df.melt(value_vars=col_list,var_name='Variable',value_name='Value')\n",
    "\n",
    "# calculate mean value per variable\n",
    "mean_values=df_melted.groupby('Variable')['Value'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25691d-32f5-49a8-ac2c-672ad39a4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b0d95-2da1-4639-ac2b-e193aea3e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom labels for following figure\n",
    "labels=[f\"{variable}: {mean_values[variable]:.2f}\" for variable in mean_values.keys()]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8d936-407b-451e-b522-44379c5671b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted['Variable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0ce8f-d200-49f4-b27e-d30cbced8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabs=['Delivery Time',\n",
    "       'Contents of Order',\n",
    "       'Order Completeness',\n",
    "       'Price for Order',\n",
    "       'Satisfaction with Courier',\n",
    "       'Satisfaction with App Experience']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d09724-857b-4ea6-897f-3391b79f3d02",
   "metadata": {},
   "source": [
    "### Figure 2: Distribution of survey results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f0772-c568-4259-9243-887e34661004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of survey results\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax=sns.countplot(data=df_melted,x='Variable',hue='Value')\n",
    "plt.suptitle('Count of Survey Results for Each Survey Question\\n1 being least satisfied and 5 being most satisfied')\n",
    "plt.xlabel('Survey Question')\n",
    "plt.ylabel('Count')\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(True,which='major')\n",
    "ax.set_xticklabels(xlabs)\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend(title='Response',loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figs/1_xdistribution.pdf')\n",
    "plt.savefig('../figs/1_xdistribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cf18d-59f5-4276-8292-b0bf9b6c4df5",
   "metadata": {},
   "source": [
    "This plot illustrates well the distribution of responses received in the survey. Although it is harder to draw conclusions from this figure, I think it is still valid to understand the overall trends in the data. Figure 3 has more explanatory value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91d264-9ae1-4c54-8d00-347da860f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup labels for mean values\n",
    "mean_values=df_melted.groupby('Variable')['Value'].mean()\n",
    "mean_values=mean_values.round(decimals=2)\n",
    "mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820cd0f2-9d15-49a5-9bb9-3908e7053a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data labels\n",
    "x=[i for i in np.arange(6)]\n",
    "y=[mean_values[i] for i in np.arange(6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b82f79-5144-407f-8e51-bf98a872eb51",
   "metadata": {},
   "source": [
    "### Figure 3: Mean response to survey question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4580fe6-20f9-47e4-b8a4-bad8a5577bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax=sns.barplot(data=df_melted,x='Variable',y='Value',ci=None,color='coral')\n",
    "plt.tight_layout(pad=10)\n",
    "# plot labels\n",
    "for i in range(len(x)):\n",
    "    plt.text(i, y[i], y[i], ha='center')\n",
    "ax.set_xticklabels(xlabs,rotation=30)\n",
    "ax.set_title('Mean Response to Survey Question')\n",
    "ax.set_ylabel('Mean Response')\n",
    "ax.set_xlabel('Survey Question')\n",
    "plt.savefig('../figs/1_xmeandistribution.pdf')\n",
    "plt.savefig('../figs/1_xmeandistribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b654d-169d-4c8a-a459-117aa35b8115",
   "metadata": {},
   "source": [
    "The delivery time and app experience had the highest mean satisfaction in the survey, with the contents having the lowest overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27563ad5-0cc4-497f-93fa-f7217d4d70f8",
   "metadata": {},
   "source": [
    "### Figure 4: Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d5e2b7-dba5-4a7b-9709-e7e2f81e73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f,ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "# cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, annot=True,\n",
    "            cbar_kws={\"shrink\": .5})\n",
    "plt.title('Correlation Matrix\\nHigher absolute value indicates stronger correlation')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save fig\n",
    "plt.savefig('../figs/1_corrmatrix.pdf')\n",
    "plt.savefig('../figs/1_corrmatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fc56b-fc49-4221-87b7-64dae7eca05e",
   "metadata": {},
   "source": [
    "The results of the correlation matrix show that if one aspect of the experience is positive, the customer will rate others positive as well. One interesting correlation to highlight is the courier and time are connected, which makes sense: the courier is the person that gives you your order, and if the courier is on time you probably will rate the courier highly too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94369155-0f3d-4c3e-ab1f-99f61743a779",
   "metadata": {},
   "source": [
    "### EDA Summary <a name='eda_sum'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc5eba-8426-469b-9ad6-4d58821f9618",
   "metadata": {},
   "source": [
    "In the dataset that we were given, roughly half of the respondents were unhappy. From a business standpoint, this is an opportunity to increase the amount of satisfied customers. Hence the survey, ostensibly to understand how the company can improve the satisfaction of their customers.\n",
    "\n",
    "The results from the survey show that the delivery time and the app experience are places where the company is doing well. Areas for improvement are ensuring that the order is prepared correctly and customers being able to find what they need when they place an order.\n",
    "\n",
    "We need to do more modeling to understand which survey questions are most important and which can be removed. We will do this in the subsequent sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d1fe5-c95e-48e8-b1a1-4701ff959762",
   "metadata": {},
   "source": [
    "## Run this section in the `lazypredict` environment <a name='lazy_predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c7189-97ee-40ca-acd8-ab083d5d09a6",
   "metadata": {},
   "source": [
    "[`lazypredict`](#https://lazypredict.readthedocs.io/en/latest/) is a very helpful package that can run through generic builds of a multitude of models in order to get a high-level understanding of the performance of these models on your particular dataset. It is a great place to start and saves a lot of time that would be spent manually exploring the accuracy of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea55c3-bb5b-46e0-a01a-c4526332360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbabe0-bc61-4812-bf38-5f67e1ad356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1922de96-1543-4266-a7d4-d3b87922cb88",
   "metadata": {},
   "source": [
    "### Specify random seed <a name='rand'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e36c1b-b441-4ff0-8094-277db1442053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to generate random integers\n",
    "\n",
    "def rand_gen(low=1,high=1e4):\n",
    "    rng=np.random.default_rng()\n",
    "    random_state=rng.integers(low=low,high=high)\n",
    "    return random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29304a-01e3-4379-b646-6e37ec02bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random seed\n",
    "seed=rand_gen()\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df5821-5d49-4a54-9e59-9a71f0889de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save random seed to file to access it later in the notebook\n",
    "with open('random_seed.txt','w') as file:\n",
    "    file.write(str(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b849850-76c1-43b8-b9ab-305cfeac12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the number got saved\n",
    "with open('random_seed.txt','r') as file:\n",
    "    saved_seed=int(file.read())\n",
    "    print(saved_seed)\n",
    "    seed=saved_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf13a36-ea38-4830-b188-c12790a21cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source:\n",
    "# https://odsc.medium.com/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine-219969c84752\n",
    "\n",
    "# set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "# set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed)\n",
    "# set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "np.random.default_rng(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afefa98-5610-43ca-807a-dea3fbc49765",
   "metadata": {},
   "source": [
    "### Read in and setup dataset <a name='read'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bcbe63-40a0-44ce-8029-f350839ad215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and setup dataset\n",
    "\n",
    "df=pd.read_csv('../data/1_data.csv')\n",
    "\n",
    "# renaming columns to preserve order\n",
    "# and make them more intelligible\n",
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "# df.dtypes\n",
    "\n",
    "X=df[[col for col in df.columns if col != 'y']].copy()\n",
    "y=df['y'].copy().astype('int8') # because it's a binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d323d74-488c-4762-8f60-66d3cd9a6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, \\\n",
    "X_test, \\\n",
    "y_train, \\\n",
    "y_test = train_test_split(X, \n",
    "                          y, \n",
    "                          test_size=0.2, \n",
    "                          stratify=y,\n",
    "                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98747f7-3a28-4069-ba5a-30dd6df914d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "Shapes of splits:\n",
    "X_train: {X_train.shape}\n",
    "X_test:  {X_test.shape}\n",
    "y_train: {y_train.shape}\n",
    "y_test:  {y_test.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19d66a-4c4c-42b5-a20b-995244c98ebd",
   "metadata": {},
   "source": [
    "### Run LazyClassifier <a name='lazy'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4e431-5c79-402f-afa8-5c9d5582940f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,\n",
    "                     ignore_warnings=True,\n",
    "                     random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadef9df-2809-4976-bdcc-9e87acc5e9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models, predictions = clf.fit(X_train=X_train,\n",
    "                              X_test=X_test,\n",
    "                              y_train=y_train,\n",
    "                              y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5022f09-7e03-4c68-9e9f-a316d12368a8",
   "metadata": {},
   "source": [
    "Results from the `LazyClassifier`:  <a name='lazy_predict_results'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c1846-dd4e-49ea-be0e-50f04040aa1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc9c46-4448-4e2a-9d33-222a8e86007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.to_csv('../joblib/1_lazypredict_20240604.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f2d13-07c6-4e05-983f-5b35d76f30b8",
   "metadata": {},
   "source": [
    "## Switch to `sklearn` environment <a name='sklearn'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a145a8-8f16-4295-b6bd-ca9858f865da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c2617-6bca-43fd-89c6-5c90f8a92c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=pd.read_csv('../joblib/1_lazypredict_20240530.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f26c08-22ab-4135-a5cb-599e7392c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c573aac-bd50-4dbd-984e-b4c0f9815811",
   "metadata": {},
   "source": [
    "After exploring alternatives, including `LGBMClassifier`, I will now use `XGBoost` instead. In a previous iteration, a previous `random_seed`, it had given me the second-highest accuracy. You'll note that XGBoost is now at a different rank in the model options. This is a lesson that I must always specify a `random_state` to ensure reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b511c6b-1b16-42b7-961d-622909cee8b4",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9814c-b8bb-4891-a954-ed577dc4faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89336421-c89f-477e-954b-4e4ab3385419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open saved random seed from earlier in the notebook\n",
    "with open('random_seed.txt','r') as file:\n",
    "    saved_seed=int(file.read())\n",
    "    print(saved_seed)\n",
    "    seed=saved_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20930b14-1d28-4d66-bdf4-8840333800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and setup dataset\n",
    "\n",
    "df=pd.read_csv('../data/1_data.csv')\n",
    "\n",
    "# renaming columns to preserve order\n",
    "# and make them more intelligible\n",
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "X=df[[col for col in df.columns if col != 'y']].copy()\n",
    "y=df['y'].copy().astype('int8') # because it's a binary\n",
    "                                # let's use less memory\n",
    "    \n",
    "X_train, \\\n",
    "X_test, \\\n",
    "y_train, \\\n",
    "y_test = train_test_split(X, \n",
    "                          y, \n",
    "                          test_size=0.2, \n",
    "                          stratify=y,\n",
    "                          random_state=seed)\n",
    "\n",
    "print(f'''\n",
    "Shapes of splits:\n",
    "X_train: {X_train.shape}\n",
    "X_test:  {X_test.shape}\n",
    "y_train: {y_train.shape}\n",
    "y_test:  {y_test.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012faf84-a2ae-4b29-a729-678e58de73c4",
   "metadata": {},
   "source": [
    "### Initial model run <a name='xgboost_initial'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fad64-7dfc-4be0-b55c-5451f5e3af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(random_state=seed)\n",
    "xgbc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgbc.predict(X_test)\n",
    "print(f'Score on test: {xgbc.score(X_test,y_test)}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226be221-974f-42f1-901a-c038bbac5235",
   "metadata": {},
   "source": [
    "The base model is not great yet. Let's keep going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee6633-66cd-4264-927b-c98e3a82b9a0",
   "metadata": {},
   "source": [
    "### Grid Search Exploration with `XGBoost`<a name='xgboost'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454bb34-5eb4-48a6-90b9-81b0e9b5af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,cross_val_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a94c80-027f-4c52-b06c-a7a1f7024953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(random_state=seed)\n",
    "\n",
    "# commenting this out because it was giving us errors\n",
    "# as the data is not a categorical dtype\n",
    "\n",
    "# specifying the k-fold so that we can control the randomness\n",
    "# statified_k_fold=StratifiedKFold(n_splits=5,\n",
    "#                                  random_state=random_state,\n",
    "#                                  shuffle=True)\n",
    "\n",
    "parameters = {\n",
    "    'alpha': [0], #(list(np.linspace(0,1,3))),\n",
    "    'gamma': [0], #(list(np.linspace(0,1,3))),\n",
    "    'lambda': (list(np.linspace(0.275,0.325,6))),\n",
    "    'learning_rate': (np.logspace(0.211,0.213,9)),\n",
    "    'max_depth': [2], #(list(np.arange(1,4))),\n",
    "    'min_child_weight': (list(np.linspace(3.5,4.5,9))),\n",
    "    'n_estimators': (np.arange(53,58))\n",
    "}\n",
    "\n",
    "# same here - I wanted to control the kfolds\n",
    "# but it was giving me trouble\n",
    "\n",
    "# Convert categorical features to one-hot encoded features\n",
    "# X_train_encoded = pd.get_dummies(X_train)\n",
    "\n",
    "grid_search = GridSearchCV(xgbc, \n",
    "                           parameters, \n",
    "                           cv = 5,#statified_k_fold, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 0)\n",
    "\n",
    "# grid_search.fit(X_train_encoded, y_train)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# save trained model to pickle file\n",
    "joblib_file='../joblib/1_gridsearch_xgbc_20240530.pkl'\n",
    "joblib.dump(grid_search,joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298ad0c-beb4-4741-b4d5-727cea239986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid search file\n",
    "joblib_file='../joblib/1_gridsearch_xgbc_20240530.pkl'\n",
    "loaded_grid_search=joblib.load(joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f86f36-ae6e-41e8-b91f-a20fc5176612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best score\n",
    "print(f\"best score: {loaded_grid_search.best_score_}\")\n",
    "\n",
    "# best parameters \n",
    "print(f\"best parameters: {loaded_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4da173-94c4-4d7a-94af-4f12b2abfc70",
   "metadata": {},
   "source": [
    "List of other best scores from previous `random_seeds` and iterations below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29555a6-69cc-4890-99ba-cd070dc82e0c",
   "metadata": {},
   "source": [
    "```python\n",
    "best score: 0.64\n",
    "best parameters: {'alpha': 0, 'gamma': 0, 'lambda': 0.275, 'learning_rate': 1.625548755750484, 'max_depth': 2, 'min_child_weight': 4.375, 'n_estimators': 53}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856bf4f-5a8f-499e-a48e-528acdbdc0aa",
   "metadata": {},
   "source": [
    "```python\n",
    "best score: 0.6900000000000001\n",
    "best parameters: {'alpha': 0, 'gamma': 0, 'lambda': 0.3, 'learning_rate': 1.6292960326397223, 'max_depth': 2, 'min_child_weight': 4.0, 'n_estimators': 55}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9ab38-7f99-4905-9476-151faa640c2e",
   "metadata": {},
   "source": [
    "```python\n",
    "best score: 0.68\n",
    "best parameters: {'alpha': 0, 'gamma': 0, 'lambda': 0.275, 'learning_rate': 1.6330519478943344, 'max_depth': 2, 'min_child_weight': 3.875, 'n_estimators': 56}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e991f880-efc2-40a4-9fc1-64001640c07c",
   "metadata": {},
   "source": [
    "Let's now confirm results with running the best parameters again. I will use a pipeline as I want to ensure that I can include a `random_state` and make sure that the model understands that we're dealing with categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f2ff0-81d8-4ef6-a49b-e6fb47b12aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# X columns are categorical so they need to be OHE'd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31458f-f69b-467d-bb7d-5ee701fbff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup classifier\n",
    "model=XGBClassifier(alpha=0,\n",
    "                    gamma=0,\n",
    "                    reg_lambda=0.3,\n",
    "                    learning_rate=1.6292960326397223,\n",
    "                    max_depth=2,\n",
    "                    min_child_weight=4,\n",
    "                    n_estimators=55,\n",
    "                    random_state=seed)\n",
    "\n",
    "# preprocessor to handle categorical features, make them OHE'd\n",
    "# it will ignore any categories that are not found in X_test\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), [0, 1])\n",
    "    ])\n",
    "\n",
    "# create pipeline\n",
    "pipeline=Pipeline([\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('xgb',model)\n",
    "])\n",
    "\n",
    "# allow for five cross-validation folds\n",
    "stratified_k_fold=StratifiedKFold(n_splits=5,\n",
    "                                 random_state=seed,\n",
    "                                 shuffle=True)\n",
    "\n",
    "# perform cross-validation and print accuracy\n",
    "scores=cross_val_score(pipeline, \n",
    "                       X, \n",
    "                       y, \n",
    "                       cv=stratified_k_fold, \n",
    "                       scoring='accuracy')\n",
    "\n",
    "print('Cross-validated accuracy: '\\\n",
    "f'{scores.mean()*100:.2f}% ± {scores.std()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf566b-105f-4888-a164-70abf19dc80f",
   "metadata": {},
   "source": [
    "I'm satisfied with that. It's close enough. It's great to see that we were able to increase the accuracy from <50% to >50%. It's still not a great accuracy level, but much better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b7292-1c7b-4c49-9db7-b9f49f7e8fd2",
   "metadata": {},
   "source": [
    "### `SGDClassifier` <a name='sgdc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e8e35-4aee-4d55-b1fa-84eb93296249",
   "metadata": {},
   "source": [
    "Per the past results from the `lazypredict` [here](#lazy_predict_results), I will switch to the `SGDClassifier`. I will also employ a more in-depth pipeline to include other steps, like `RFE`, for feature elimination. This gets at the stretch goal of the company who gave us the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d085e-180f-40bb-a0c2-18179521e24b",
   "metadata": {},
   "source": [
    "We should `get_dummies` on our dataset and run a correlation matrix because I'm curious. With the dataset transformed to be OneHotEncoded, rather than staying categorical, would different correlations jump out at us? Let's see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b2dad-703d-4eb6-85c8-ddc9ac458506",
   "metadata": {},
   "source": [
    "#### `get_dummies`<a name='sgdc_dummies'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b9f95-1993-4517-befe-96a21b419633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and setup dataset again\n",
    "\n",
    "df=pd.read_csv('../data/1_data.csv')\n",
    "\n",
    "# renaming columns to preserve order\n",
    "# and make them more intelligible\n",
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "X=df[[col for col in df.columns if col != 'y']].copy()\n",
    "y=df['y'].copy().astype('int8') # because it's a binary\n",
    "                                # let's use less memory\n",
    "\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360c1c2-cb6b-44eb-aae3-8f802635596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6321a-2357-4a5d-b42e-1d1d8fd13844",
   "metadata": {},
   "source": [
    "`pd.get_dummies` requires the data be categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0789f2-bfc0-4353-a2c3-c8fce2c48506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat=X.copy()\n",
    "\n",
    "for col in X_cat.columns:\n",
    "    X_cat[col] = X_cat[col].astype('category')\n",
    "    \n",
    "X_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3abffa2-0e67-442c-82a2-f9fcabe3ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe=pd.get_dummies(data=X_cat,\n",
    "                     prefix=list(X_cat.columns),\n",
    "                     drop_first=False) # I want to \n",
    "                                       # see all survey responses\n",
    "                                       # that are in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1a838-f46a-41cb-bdc4-afdcad453013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_ohe.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f,ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "# cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, annot=True,\n",
    "            cbar_kws={\"shrink\": .5},\n",
    "            annot_kws={\"size\":5})\n",
    "plt.title(\"Correlation Matrix for OHE'd Data\\nHigher absolute value indicates stronger correlation (positive [red] or negative [blue])\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# save fig\n",
    "plt.savefig('../figs/1_corrmatrix_ohe.pdf')\n",
    "plt.savefig('../figs/1_corrmatrix_ohe.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be663e3e-51ff-40e6-a5e9-47c16445f37e",
   "metadata": {},
   "source": [
    "Nothing much to learn here except that if a specific category scored high, other categories likely scored high. This is also true if categories scored low. Some categories are missing as there is no data recorded for them. For example, no respondent scored `time` as a `2`.\n",
    "\n",
    "I'm curious why, for example, people that scored the `app` as `4` were not likely to score the `time` as `5`. This may be explained later in our modeling and statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761872e1-587b-4722-a7e5-04eeda730a47",
   "metadata": {},
   "source": [
    "#### `train_test_split` on the OHE'd dataset <a name='tts_ohe'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd601bb2-5f99-49f0-9f29-7824e2135a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train_ohe, \\\n",
    "X_test_ohe, \\\n",
    "y_train_ohe, \\\n",
    "y_test_ohe = train_test_split(X_ohe, \n",
    "                          y, \n",
    "                          test_size=0.2, \n",
    "                          stratify=y,\n",
    "                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3bf61-67e1-441f-bfa5-80816ac510f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that the split occurred\n",
    "print(f'''\n",
    "Shapes of splits:\n",
    "X_train: {X_train_ohe.shape}\n",
    "X_test:  {X_test_ohe.shape}\n",
    "y_train: {y_train_ohe.shape}\n",
    "y_test:  {y_test_ohe.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb61c6-2db9-4025-a526-42d31efb1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcfeee-a408-4eee-9c0c-e4ac1b6a3110",
   "metadata": {},
   "source": [
    "Great, now we're ready for a new pipeline with `SGDClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef467a6-b1ee-4c96-919e-210ae1284d24",
   "metadata": {},
   "source": [
    "#### New Pipeline with `SGDClassifier` and OneHotEncoded X data <a name='pipe_ohe'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299773a1-cc52-43c0-a0e2-a3f892202111",
   "metadata": {},
   "source": [
    "##### More notes on the Pipeline choices:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9880d767-12c4-4e2c-99ec-a61f5add7a5e",
   "metadata": {},
   "source": [
    "* `RFE` is great for feature selection, as it can help you understand which features are most important. RFE requires a base estimator to assign weights to features. We can use a logistic regression model.\n",
    "* We're using the `SGDClassifier` as the final step in our pipeline as it scored the top accuracy in our `lazypredict` run.\n",
    "* We'll set up a grid search so that we can explore the hyperparameter space to find the best hyperparameters for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aacc66-0bd6-4c39-bc69-e23cd6416bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308d60a-683c-40c5-ae65-3f32d2984e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the k-fold so that we can control the randomness\n",
    "\n",
    "stratified_k_fold=StratifiedKFold(n_splits=5,\n",
    "                                 random_state=seed,\n",
    "                                 shuffle=True)\n",
    "\n",
    "estimators=[\n",
    "    ('rfe',RFE(estimator=LogisticRegression(random_state=seed))),\n",
    "    ('sgd',SGDClassifier(random_state=seed))]\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'rfe__n_features_to_select': list(np.arange(1, 7)),\n",
    "        'rfe__importance_getter': ['feature_importances_','auto'],\n",
    "        'sgd__max_iter': list(np.logspace(2, 5, 4).astype('int')),\n",
    "        'sgd__alpha': list(np.logspace(-5, -1, 5)),\n",
    "        'sgd__loss': ['hinge', 'log_loss', 'modified_huber'],\n",
    "        'sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'sgd__learning_rate': ['optimal'],\n",
    "        'rfe__estimator': [LogisticRegression(random_state=seed)],\n",
    "        'rfe__importance_getter': ['auto']\n",
    "    },\n",
    "    {\n",
    "        'rfe__n_features_to_select': list(np.arange(1, 7)),\n",
    "        'sgd__max_iter': list(np.logspace(2, 5, 4).astype('int')),\n",
    "        'sgd__alpha': list(np.logspace(-5, -1, 5)),\n",
    "        'sgd__loss': ['hinge', 'log_loss', 'modified_huber'],\n",
    "        'sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'sgd__learning_rate': ['optimal'],\n",
    "        'rfe__estimator': [RandomForestClassifier(random_state=seed)],\n",
    "        'rfe__importance_getter': ['auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "# perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           param_grid,\n",
    "                           cv=stratified_k_fold,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_ohe, y_train_ohe)\n",
    "\n",
    "# save trained model to pickle file\n",
    "joblib_file='../joblib/1_gridsearch_rfe_sgd_20240530.pkl'\n",
    "joblib.dump(grid_search,joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177e10c-d8fe-4b18-bf51-8fc2ab9b9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid search file\n",
    "joblib_file='../joblib/1_gridsearch_rfe_sgd_20240530.pkl'\n",
    "loaded_grid_search=joblib.load(joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a361a0c-2c9e-4345-8478-aa83c26012c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best score\n",
    "print(f\"best score: {loaded_grid_search.best_score_}\")\n",
    "\n",
    "# best parameters \n",
    "print(f\"best parameters: {loaded_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec54efb-22b0-474e-b301-97c74477ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef9769-e680-4b04-b671-46b089ec8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the best model\n",
    "y_pred_ohe = loaded_grid_search.best_estimator_.predict(X_test_ohe)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test_ohe, y_pred_ohe),\n",
    "    'precision': precision_score(y_test_ohe, y_pred_ohe),\n",
    "    'recall': recall_score(y_test_ohe, y_pred_ohe),\n",
    "    'f1': f1_score(y_test_ohe, y_pred_ohe)\n",
    "}\n",
    "\n",
    "print(\"Test Accuracy:\", metrics['accuracy'])\n",
    "print(\"Precision:    \", metrics['precision'])\n",
    "print(\"Recall:       \", metrics['recall'])\n",
    "print(\"F1 Score:     \", metrics['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06feccc2-0bd8-447e-a111-1c79ef5cd9dd",
   "metadata": {},
   "source": [
    "This result is quite terrible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e29103-42e8-404b-9318-1c84df88addc",
   "metadata": {},
   "source": [
    "Confirm that the accuracy percentage is based on `X_test` and not `X_train` - so if we run the cell below, we should get the same accuracy from the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a92ca-a958-4e6f-ab0b-8a2174d86720",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ohe = loaded_grid_search.best_estimator_.predict(X_train_ohe)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_train_ohe, y_pred_ohe),\n",
    "    'precision': precision_score(y_train_ohe, y_pred_ohe),\n",
    "    'recall': recall_score(y_train_ohe, y_pred_ohe),\n",
    "    'f1': f1_score(y_train_ohe, y_pred_ohe)\n",
    "}\n",
    "\n",
    "print(\"Test Accuracy:\", metrics['accuracy'])\n",
    "print(\"Precision:    \", metrics['precision'])\n",
    "print(\"Recall:       \", metrics['recall'])\n",
    "print(\"F1 Score:     \", metrics['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42035f11-a1f0-4681-bd0c-6f38c8b8ee7d",
   "metadata": {},
   "source": [
    "##### Extracting the most important features from the dataset: <a name='rfe_ohe'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3fde0-96cd-4661-aefe-bd30278622c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best estimator from grid search\n",
    "best_estimator=loaded_grid_search.best_estimator_\n",
    "\n",
    "# access RFE transformer within pipeline\n",
    "rfe=best_estimator.named_steps['rfe']\n",
    "\n",
    "# get selected features\n",
    "selected_features_indices=rfe.support_\n",
    "\n",
    "# extract names of selected features\n",
    "selected_features=X_train_ohe.columns[selected_features_indices]\n",
    "\n",
    "print(f\"The top features that are most important:\\n{selected_features}\")\n",
    "\n",
    "# obtain ranking of features\n",
    "feature_ranking=rfe.ranking_\n",
    "\n",
    "# feature names\n",
    "feature_names=X_train_ohe.columns\n",
    "\n",
    "# create dataframe to store feature names and rankings\n",
    "feature_ranking_df=pd.DataFrame({'Feature': feature_names,\n",
    "                                 'Ranking': feature_ranking})\n",
    "\n",
    "feature_ranking_df=feature_ranking_df.sort_values(by='Ranking')\n",
    "\n",
    "# arbitrary subset of the entire df\n",
    "# (the entire df includes all columns and their importance rank)\n",
    "# feature_ranking_df\n",
    "feature_ranking_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e30ad9-469e-43a0-b702-22f4782d36d0",
   "metadata": {},
   "source": [
    "This is really great to see, that the `RFE` was able to pull out what it thinks are the most important features. It is not as informative for a human, as these features are a binary representation of categorical data. Let's try running the non-binary version of the dataset through the trained model. Maybe we'll get more informative results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0edc58-1fe4-4bd2-8f50-fbe16261cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50893b-f4e4-4f18-9899-b0098fd0beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature rankings\n",
    "feature_ranking_df.to_csv('../data/1_feature_ranking_df_20240530.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3d10e5-4c70-458a-acca-4b9e8968cb81",
   "metadata": {},
   "source": [
    "#### New pipeline with `SGDClassifier` and categorical (not OHE'd) X data <a name='pipe_notohe'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7db04-a434-4921-a246-36345a904511",
   "metadata": {},
   "source": [
    "##### Redefine X data without OneHotEncodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce777b96-625a-4e84-b9f6-ee1b45076ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and setup dataset again\n",
    "\n",
    "df=pd.read_csv('../data/1_data.csv')\n",
    "\n",
    "# renaming columns to preserve order\n",
    "# and make them more intelligible\n",
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "X=df[[col for col in df.columns if col != 'y']].copy()\n",
    "y=df['y'].copy().astype('int8') # because it's a binary\n",
    "                                # let's use less memory\n",
    "\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9a109-521d-41d6-98d3-6fecf38b3012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e0570-85a7-47a5-8ec7-fb55632a7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat=X.copy()\n",
    "\n",
    "for col in X_cat.columns:\n",
    "    X_cat[col] = X_cat[col].astype('category')\n",
    "    \n",
    "X_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d5c84-eb7d-4b99-8c92-c269eb10822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train_cat, \\\n",
    "X_test_cat, \\\n",
    "y_train_cat, \\\n",
    "y_test_cat = train_test_split(X_cat, \n",
    "                          y, \n",
    "                          test_size=0.2, \n",
    "                          stratify=y,\n",
    "                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81caa2f6-f332-4a72-b909-da06f85cd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1317b8a-b26c-4956-871e-95cd3eb1d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e1c82-f9ac-4a7d-bafb-f613d2faedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the k-fold so that we can control the randomness\n",
    "stratified_k_fold=StratifiedKFold(n_splits=5,\n",
    "                                 random_state=seed,\n",
    "                                 shuffle=True)\n",
    "\n",
    "estimators=[\n",
    "    ('rfe',RFE(estimator=LogisticRegression(random_state=seed))),\n",
    "    ('sgd',SGDClassifier(random_state=seed))]\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'rfe__n_features_to_select': list(np.arange(1, 7)),\n",
    "        'rfe__importance_getter': ['feature_importances_','auto'],\n",
    "        'sgd__max_iter': list(np.logspace(2, 5, 4).astype('int')),\n",
    "        'sgd__alpha': list(np.logspace(-5, -1, 5)),\n",
    "        'sgd__loss': ['hinge', 'log_loss', 'modified_huber'],\n",
    "        'sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'sgd__learning_rate': ['optimal'],\n",
    "        'rfe__estimator': [LogisticRegression(random_state=seed)],\n",
    "        'rfe__importance_getter': ['auto']\n",
    "    },\n",
    "    {\n",
    "        'rfe__n_features_to_select': list(np.arange(1, 7)),\n",
    "        'sgd__max_iter': list(np.logspace(2, 5, 4).astype('int')),\n",
    "        'sgd__alpha': list(np.logspace(-5, -1, 5)),\n",
    "        'sgd__loss': ['hinge', 'log_loss', 'modified_huber'],\n",
    "        'sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'sgd__learning_rate': ['optimal'],\n",
    "        'rfe__estimator': [RandomForestClassifier(random_state=seed)],\n",
    "        'rfe__importance_getter': ['auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "# perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           param_grid,\n",
    "                           cv=stratified_k_fold,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# note that this is now on the categorical\n",
    "# X_train and y_train, not OHE'd data\n",
    "grid_search.fit(X_train_cat, y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e5173-d50d-44f3-95cc-3bd8ee1e2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model to pickle file\n",
    "# but first, get unique datetime tag \n",
    "# to differentiate pickle files\n",
    "from datetime import datetime\n",
    "\n",
    "# get current date and time\n",
    "current_datetime=datetime.now()\n",
    "\n",
    "# print current date and time to check\n",
    "print(current_datetime)\n",
    "\n",
    "# format the datetime for a filename\n",
    "datetime_suffix=current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# create filename with the datetime suffix\n",
    "joblib_file=f'../joblib/1_gridsearch_rfe_sgd_{datetime_suffix}.pkl'\n",
    "\n",
    "# save model\n",
    "joblib.dump(grid_search,joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe5b79-833b-4b2c-842b-396d7fe9ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "joblib_file=f'../joblib/1_gridsearch_rfe_sgd_{datetime_suffix}.pkl'\n",
    "loaded_grid_search=joblib.load(joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff56066-1996-410f-a683-341c04b4ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best score\n",
    "print(f\"best score: {loaded_grid_search.best_score_}\")\n",
    "\n",
    "# best parameters \n",
    "print(f\"best parameters: {loaded_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b5af8-6ab1-4f56-923c-ed9321f8c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the best model\n",
    "y_pred_cat = loaded_grid_search.best_estimator_.predict(X_test_cat)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test_cat, y_pred_cat),\n",
    "    'precision': precision_score(y_test_cat, y_pred_cat),\n",
    "    'recall': recall_score(y_test_cat, y_pred_cat),\n",
    "    'f1': f1_score(y_test_cat, y_pred_cat)\n",
    "}\n",
    "\n",
    "print(\"Test Accuracy:\", metrics['accuracy'])\n",
    "print(\"Precision:    \", metrics['precision'])\n",
    "print(\"Recall:       \", metrics['recall'])\n",
    "print(\"F1 Score:     \", metrics['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea75361-d0b6-4b41-b5ab-ce045be2f8ec",
   "metadata": {},
   "source": [
    "Not a great accuracy result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2601a-0ae6-44a9-a413-2cae2b3ca207",
   "metadata": {},
   "source": [
    "##### Extracting the most important features from the dataset: <a name='rfe_notohe'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce381d-50f4-431e-a7b5-a581e2adb14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best estimator from grid search\n",
    "best_estimator=loaded_grid_search.best_estimator_\n",
    "\n",
    "# access RFE transformer within pipeline\n",
    "rfe=best_estimator.named_steps['rfe']\n",
    "\n",
    "# get selected features\n",
    "selected_features_indices=rfe.support_\n",
    "\n",
    "# extract names of selected features\n",
    "selected_features=X_train_cat.columns[selected_features_indices]\n",
    "\n",
    "print(f\"The top features that are most important:\\n{selected_features}\")\n",
    "\n",
    "# obtain ranking of features\n",
    "feature_ranking=rfe.ranking_\n",
    "\n",
    "# feature names\n",
    "feature_names=X_train_cat.columns\n",
    "\n",
    "# create dataframe datetime_suffixture names and rankings\n",
    "feature_ranking_df_cat=pd.DataFrame({'Feature': feature_names,\n",
    "                                 'Ranking': feature_ranking})\n",
    "\n",
    "feature_ranking_df_cat=feature_ranking_df_cat.sort_values(by='Ranking')\n",
    "\n",
    "feature_ranking_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4151f18-7608-4e3d-814a-9d5c6e0e68b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature rankings\n",
    "feature_ranking_df_cat.to_csv('../data/1_feature_ranking_df_cat_20240531.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fad59-9978-460b-88de-7767ca5f5cca",
   "metadata": {},
   "source": [
    "This feature ranking is a lot easier to understand. Here, we can see that time, contents, and the performance of the courier are most important for this iteration of the model. Interestingly, price is not an important predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3cb1b-6c3e-4e42-8223-a32d21a321ef",
   "metadata": {},
   "source": [
    "#### Final pipeline/grid search with thresholded data <a name='thresholded_grid'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce0038-c1fa-4ae4-b99e-5426843ac841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholding function\n",
    "# if the person scored a category as a 4 or 5,\n",
    "# we give a value of 1. Otherwise, we give it a 0\n",
    "threshold_func = lambda x: 1 if x >= 4 else 0\n",
    "\n",
    "# apply the function to the dataframe\n",
    "X_threshold = X.map(threshold_func)\n",
    "X_threshold.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5046b0-eaac-47cb-aa85-0ccdbebbbd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train_threshold, \\\n",
    "X_test_threshold, \\\n",
    "y_train_threshold, \\\n",
    "y_test_threshold = train_test_split(X_threshold, \n",
    "                          y, \n",
    "                          test_size=0.2, \n",
    "                          stratify=y,\n",
    "                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006253ba-0097-456f-94ae-a9f21ec853d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_threshold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6678966-5d35-4e96-a449-d77c7084e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_threshold.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557122d-0fa7-4c00-99fe-a2a882ae151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the k-fold so that we can control the randomness\n",
    "stratified_k_fold=StratifiedKFold(n_splits=5,\n",
    "                                 random_state=seed,\n",
    "                                 shuffle=True)\n",
    "\n",
    "estimators=[\n",
    "    ('rfe',RFE(estimator=LogisticRegression(random_state=seed))),\n",
    "    ('sgd',SGDClassifier(random_state=seed))]\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'rfe__n_features_to_select': list(np.arange(1, 7)),\n",
    "        'rfe__importance_getter': ['feature_importances_','auto'],\n",
    "        'sgd__max_iter': list(np.logspace(2, 5, 4).astype('int')),\n",
    "        'sgd__alpha': list(np.logspace(-5, -1, 5)),\n",
    "        'sgd__loss': ['hinge', 'log_loss', 'modified_huber'],\n",
    "        'sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'sgd__learning_rate': ['optimal'],\n",
    "        'rfe__estimator': [LogisticRegression(random_state=seed)],\n",
    "        'rfe__importance_getter': ['auto']\n",
    "    },\n",
    "    {\n",
    "        'rfe__n_features_to_select': list(np.arange(1, 7)),\n",
    "        'sgd__max_iter': list(np.logspace(2, 5, 4).astype('int')),\n",
    "        'sgd__alpha': list(np.logspace(-5, -1, 5)),\n",
    "        'sgd__loss': ['hinge', 'log_loss', 'modified_huber'],\n",
    "        'sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'sgd__learning_rate': ['optimal'],\n",
    "        'rfe__estimator': [RandomForestClassifier(random_state=seed)],\n",
    "        'rfe__importance_getter': ['auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "# perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           param_grid,\n",
    "                           cv=stratified_k_fold,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "# X_train and y_train on thresholded data\n",
    "grid_search.fit(X_train_threshold, y_train_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354da2b0-c703-4126-97cf-9ec49a6440e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model to pickle file\n",
    "# but first, get unique datetime tag \n",
    "# to differentiate pickle files\n",
    "from datetime import datetime\n",
    "\n",
    "# get current date and time\n",
    "current_datetime=datetime.now()\n",
    "\n",
    "# print current date and time to check\n",
    "print(current_datetime)\n",
    "\n",
    "# format the datetime for a filename\n",
    "datetime_suffix=current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# create filename with the datetime suffix\n",
    "joblib_file=f'../joblib/1_gridsearch_rfe_sgd_threshold_{datetime_suffix}.pkl'\n",
    "\n",
    "# save model\n",
    "joblib.dump(grid_search,joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2dbc5d-440a-469b-a8ea-3582e6067d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "joblib_file=f'../joblib/1_gridsearch_rfe_sgd_threshold_{datetime_suffix}.pkl'\n",
    "loaded_grid_search=joblib.load(joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8389c607-5986-4f82-a1c7-0f99e2b4e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best score\n",
    "print(f\"best score: {loaded_grid_search.best_score_}\")\n",
    "\n",
    "# best parameters \n",
    "print(f\"best parameters: {loaded_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac33d85-24e4-4525-9a62-6f2f3b34eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the best model\n",
    "y_pred_threshold = loaded_grid_search.best_estimator_.predict(X_test_threshold)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test_threshold, y_pred_threshold),\n",
    "    'precision': precision_score(y_test_threshold, y_pred_threshold),\n",
    "    'recall': recall_score(y_test_threshold, y_pred_threshold),\n",
    "    'f1': f1_score(y_test_threshold, y_pred_threshold)\n",
    "}\n",
    "\n",
    "print(\"Test Accuracy:\", metrics['accuracy'])\n",
    "print(\"Precision:    \", metrics['precision'])\n",
    "print(\"Recall:       \", metrics['recall'])\n",
    "print(\"F1 Score:     \", metrics['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ef4cd-5731-47ab-8e24-ec29806bbee5",
   "metadata": {},
   "source": [
    "Still a pretty dismal accuracy result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f86bd-930c-4395-9479-19940a1f2e9c",
   "metadata": {},
   "source": [
    "##### Extracting the most important features from the dataset: <a name='rfe_threshold'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633ef59-c988-4c53-af24-4f1b8cc52c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best estimator from grid search\n",
    "best_estimator=loaded_grid_search.best_estimator_\n",
    "\n",
    "# access RFE transformer within pipeline\n",
    "rfe=best_estimator.named_steps['rfe']\n",
    "\n",
    "# get selected features\n",
    "selected_features_indices=rfe.support_\n",
    "\n",
    "# extract names of selected features\n",
    "selected_features=X_train_cat.columns[selected_features_indices]\n",
    "\n",
    "print(f\"The top features that are most important:\\n{selected_features}\")\n",
    "\n",
    "# obtain ranking of features\n",
    "feature_ranking=rfe.ranking_\n",
    "\n",
    "# feature names\n",
    "feature_names=X_train_cat.columns\n",
    "\n",
    "# create dataframe datetime_suffixture names and rankings\n",
    "feature_ranking_df_threshold=pd.DataFrame({'Feature': feature_names,\n",
    "                                 'Ranking': feature_ranking})\n",
    "\n",
    "feature_ranking_df_threshold=feature_ranking_df_cat.sort_values(by='Ranking')\n",
    "\n",
    "feature_ranking_df_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745dcd1-4182-4ae2-90f0-0ddd8f11ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature rankings\n",
    "feature_ranking_df_threshold.to_csv('../data/1_feature_ranking_df_threshold_20240531.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2314a29f-57de-4512-973f-204dea12434a",
   "metadata": {},
   "source": [
    "This is a promising result, in that the same features are being shown as important here as well as in previous iterations of the pipeline above. `time`, `contents`, and `courier` are equally important, while `app`, `complete`, and `price` are less important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422a138-a51d-45bc-90da-ac7a748b40a0",
   "metadata": {},
   "source": [
    "Our accuracies are not consistent, so we will shift to using the `hyperopt` package to help us arrive at more optimal hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef40be09-ecd2-493d-9774-aa5f0564fd6d",
   "metadata": {},
   "source": [
    "### `hyperopt` <a name='hyper'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad3378-4841-4bea-b40d-234ad5989622",
   "metadata": {},
   "source": [
    "Tutorials are [here](#http://hyperopt.github.io/hyperopt/tutorials/01.BasicTutorial/) and [here](#https://towardsdev.com/optimizing-hyperparameters-with-hyperopt-a-hands-on-tutorial-2839efcbc177?gi=de88b6cfe1cd).  \n",
    "And I'm following examples from [here](#https://github.com/hyperopt/hyperopt-sklearn) and [here](#https://medium.com/district-data-labs/parameter-tuning-with-hyperopt-faa86acdfdce)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96fb511-3e7e-49d5-b404-47ed91f03ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b410ac0-bace-4958-8c76-5402b553e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access random seed\n",
    "with open('random_seed.txt','r') as file:\n",
    "    saved_seed=int(file.read())\n",
    "    print(saved_seed)\n",
    "    seed=saved_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94c842-6bc6-4314-a87a-a633b99d79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source:\n",
    "# https://odsc.medium.com/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine-219969c84752\n",
    "\n",
    "# set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "# set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed)\n",
    "# set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30698df-706e-4755-b9ab-825365e054c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and setup dataset again\n",
    "\n",
    "df=pd.read_csv('../data/1_data.csv')\n",
    "\n",
    "# renaming columns to preserve order\n",
    "# and make them more intelligible\n",
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "X=df[[col for col in df.columns if col != 'y']].copy()\n",
    "y=df['y'].copy().astype('int8') # because it's a binary\n",
    "                                # let's use less memory\n",
    "\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"y shape:\",y.shape)\n",
    "\n",
    "# define thresholding function\n",
    "# if the person scored a category as a 4 or 5,\n",
    "# we give a value of 1. Otherwise, we give it a 0\n",
    "threshold_func = lambda x: 1 if x >= 4 else 0\n",
    "\n",
    "# apply the function to the dataframe\n",
    "X_threshold = X.applymap(threshold_func)\n",
    "X_threshold\n",
    "\n",
    "# train/test split\n",
    "X_train_threshold, \\\n",
    "X_test_threshold, \\\n",
    "y_train_threshold, \\\n",
    "y_test_threshold = train_test_split(X_threshold, \n",
    "                          y, \n",
    "                          test_size=0.2, \n",
    "                          stratify=y,\n",
    "                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedde8be-e2da-4abc-97a6-09b82fa54bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_threshold.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0071200-bce4-4e7e-b8b0-ee1b0e04aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cafb14-0296-4b37-952d-a72139166b6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run `hyperopt` with `RFE` and `ExtraTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a848c4-e73a-4434-a405-006fa737a201",
   "metadata": {},
   "source": [
    "##### Notes on `hyperopt` parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6b87e-c10b-48fa-8416-8518303594c2",
   "metadata": {},
   "source": [
    "* Using `RFE` to select which features are most important\n",
    "* `ExtraTreeClassifier` is used as the final model as it gave good results from the `LazyPredict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2772d7a6-f490-435b-b1f0-94563ce0ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperoptOptimizer:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.best = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def hyperopt_train_test(self, params):\n",
    "        # Extract RFE parameters\n",
    "        n_features_to_select = params['n_features_to_select']\n",
    "        del params['n_features_to_select']\n",
    "        \n",
    "        # extract classifier type\n",
    "        t = params['type']\n",
    "        del params['type']\n",
    "        \n",
    "        # define classifier based on type\n",
    "        if t == 'extratrees':\n",
    "            clf = ExtraTreesClassifier(**params)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        # define RFE with the classifier\n",
    "        rfe = RFE(estimator=clf, \n",
    "                  n_features_to_select=n_features_to_select)\n",
    "        \n",
    "        # perform cross-validation\n",
    "        return cross_val_score(rfe, self.X, self.y).mean()\n",
    "\n",
    "    def objective(self, params):\n",
    "        self.count += 1\n",
    "        acc = self.hyperopt_train_test(params.copy())\n",
    "        if acc > self.best:\n",
    "            print('new best:', acc, 'using', params['type'])\n",
    "            self.best = acc\n",
    "        if self.count % 25 == 0:\n",
    "            print('iters:', self.count, ', acc:', acc, 'using', params)\n",
    "        return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "# define hyperparameter space\n",
    "space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'extratrees',\n",
    "        'n_features_to_select': hp.choice('n_features_to_select', \n",
    "                                          range(1, X.shape[1]+1)),\n",
    "        'n_estimators': hp.choice('n_estimators', range(10, 100)),\n",
    "        'max_depth': hp.choice('max_depth', range(1, 25)),\n",
    "        'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "        'random_state': seed\n",
    "    },\n",
    "])\n",
    "\n",
    "# instantiate optimizer\n",
    "optimizer = HyperoptOptimizer(X_threshold, y)\n",
    "\n",
    "# initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "rstate = np.random.default_rng(seed)\n",
    "\n",
    "# run optimization\n",
    "best = fmin(optimizer.objective, \n",
    "            space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=100, \n",
    "            trials=trials,\n",
    "            rstate=rstate,\n",
    "            return_argmin=False)\n",
    "print('best:')\n",
    "print(best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c36614-d932-4fa6-a67d-be1b7979770e",
   "metadata": {},
   "source": [
    "##### Save best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf1a19-0576-4c3c-8ac3-f6ae4867e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24615eed-6d3b-45f9-a348-8ac780c45bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# get current date and time\n",
    "current_datetime=datetime.now()\n",
    "\n",
    "# print current date and time to check\n",
    "print(current_datetime)\n",
    "\n",
    "# format the datetime for a filename\n",
    "datetime_suffix=current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# create filename with the datetime suffix\n",
    "file_name=f'../joblib/1_hyperopt_bestparams_{datetime_suffix}.json'\n",
    "\n",
    "# save model\n",
    "with open(file_name,'w') as file:\n",
    "    file.write(json.dumps(best,default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2279be1f-9a95-474d-8f1a-29ddf16c3a38",
   "metadata": {},
   "source": [
    "##### Run the best parameters on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd11458-180b-44dd-9a2a-d95f9f1f7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract best params file\n",
    "with open(file_name,'r') as file:\n",
    "    best_params=json.load(file)\n",
    "    \n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c7039-557b-4d48-9bdc-029bab2ab4db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract best parameters\n",
    "best_n_features_to_select = best_params['n_features_to_select']\n",
    "del best_params['n_features_to_select']\n",
    "best_type = best_params['type']\n",
    "del best_params['type']\n",
    "\n",
    "# train final model using best parameters\n",
    "if best_type == 'extratrees':\n",
    "    final_clf = ExtraTreesClassifier(**best_params)\n",
    "    \n",
    "# define RFE with final classifier\n",
    "final_rfe = RFE(estimator=final_clf, \n",
    "                n_features_to_select=best_n_features_to_select)\n",
    "\n",
    "# fit final model on entire training set\n",
    "final_rfe.fit(X_train_threshold, y_train_threshold)\n",
    "\n",
    "# evaluate final model on test set\n",
    "final_score = final_rfe.score(X_test_threshold, y_test_threshold)\n",
    "print('Final test score:', final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da1281-1206-482d-a9d3-21cc64aec000",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e1d8b-e590-451b-8dd1-c7b3f19dbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()[1]/y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825f0d2-f5bc-478e-af00-9d2a536b51d9",
   "metadata": {},
   "source": [
    "## Run this section in the `lightgbm` environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b5bc6-7bcb-408a-9d64-fe3a4d2974c9",
   "metadata": {},
   "source": [
    "Import necessary packages and read in data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61904b7e-b9d2-4635-8e7c-bd195f8c4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ab6d60-6853-4038-8069-c17d16e2cd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1574\n"
     ]
    }
   ],
   "source": [
    "# open saved random seed from earlier in the notebook\n",
    "with open('random_seed.txt','r') as file:\n",
    "    saved_seed=int(file.read())\n",
    "    print(saved_seed)\n",
    "    seed=saved_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f0cdbf-5007-434c-9585-9896b563ca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes of splits:\n",
      "X_train: (100, 6)\n",
      "X_test:  (26, 6)\n",
      "y_train: (100,)\n",
      "y_test:  (26,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in and setup dataset\n",
    "\n",
    "df=pd.read_csv('../data/1_data.csv')\n",
    "\n",
    "# renaming columns to preserve order\n",
    "# and make them more intelligible\n",
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "X=df[[col for col in df.columns if col != 'y']].copy()\n",
    "y=df['y'].copy().astype('int8') # because it's a binary\n",
    "                                # let's use less memory\n",
    "    \n",
    "X_train, \\\n",
    "X_test, \\\n",
    "y_train, \\\n",
    "y_test = train_test_split(X, \n",
    "                          y, \n",
    "                          test_size=0.2, \n",
    "                          stratify=y,\n",
    "                          random_state=seed)\n",
    "\n",
    "print(f'''\n",
    "Shapes of splits:\n",
    "X_train: {X_train.shape}\n",
    "X_test:  {X_test.shape}\n",
    "y_train: {y_train.shape}\n",
    "y_test:  {y_test.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03c20e6-4fa2-4935-98ed-b82c2a0a60f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_time</th>\n",
       "      <th>b_contents</th>\n",
       "      <th>c_complete</th>\n",
       "      <th>d_price</th>\n",
       "      <th>e_courier</th>\n",
       "      <th>f_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_time  b_contents  c_complete  d_price  e_courier  f_app\n",
       "0       0           0           0        1          0      1\n",
       "1       0           0           0        1          1      0\n",
       "2       1           0           0        0          0      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define thresholding function\n",
    "# if the person scored a category as a 4 or 5,\n",
    "# we give a value of 1. Otherwise, we give it a 0\n",
    "threshold_func = lambda x: 1 if x >= 4 else 0\n",
    "\n",
    "# apply the function to the dataframe\n",
    "X_threshold = X.map(threshold_func)\n",
    "X_threshold.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d84f4a-2652-45fc-8814-00be7a0a7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train_threshold, \\\n",
    "X_test_threshold, \\\n",
    "y_train_threshold, \\\n",
    "y_test_threshold = train_test_split(X_threshold, \n",
    "                          y, \n",
    "                          test_size=0.2, \n",
    "                          stratify=y,\n",
    "                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e729a35-d950-48a9-9141-52cfe30376a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_threshold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74b26f2-6e8e-4342-b155-de5909d8a6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_time</th>\n",
       "      <th>b_contents</th>\n",
       "      <th>c_complete</th>\n",
       "      <th>d_price</th>\n",
       "      <th>e_courier</th>\n",
       "      <th>f_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a_time  b_contents  c_complete  d_price  e_courier  f_app\n",
       "74        1           0           1        1          1      1\n",
       "121       1           0           0        1          1      0\n",
       "65        1           0           0        1          1      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_threshold.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356501b-8702-47cc-a88f-14df3c8fe7b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run `hyperopt` with `RFE` and `LGBMClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0fa6a-a2bc-4506-9b37-2b680cda304d",
   "metadata": {},
   "source": [
    "##### Notes on `hyperopt` parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd646b-7b8f-4c97-b0ca-65a614d4fa46",
   "metadata": {},
   "source": [
    "* Using `RFE` to select which features are most important\n",
    "* `LGBMClassifier` is used as the final model as it also yielded good generic results from the `LazyPredict`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a17d7-2b46-4fdd-95b7-5b135b70b28c",
   "metadata": {},
   "source": [
    "Run base model to compare with `hyperopt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dacf187-36b6-42b6-8df6-d1747e5b9548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model=LGBMClassifier(random_state=seed,verbose=-1)\n",
    "print(model)\n",
    "model.fit(X_train_threshold,y_train_threshold)\n",
    "print(\"fitting model\")\n",
    "y_pred=model.predict(X_test_threshold,verbose=-1)\n",
    "print(y_pred)\n",
    "accuracy=accuracy_score(y_test_threshold,y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041f4d7-f27c-4436-8fcd-720a16e748b0",
   "metadata": {},
   "source": [
    "An accuracy of 58% on the base model is already an improvement. Let's now turn to `hyperopt` to see if we can improve the accuracy even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4330b-b2ce-4d79-88e6-0fa915c834e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best:                                                                                     \n",
      "0.4523076923076923                                                                            \n",
      "using                                                                                         \n",
      "lgbm                                                                                          \n",
      "new best:                                                                                     \n",
      "0.5476923076923077                                                                            \n",
      "using                                                                                         \n",
      "lgbm                                                                                          \n",
      "new best:                                                                                     \n",
      "0.5636923076923076                                                                            \n",
      "using                                                                                         \n",
      "lgbm                                                                                          \n",
      "new best:                                                                                     \n",
      "0.5716923076923076                                                                            \n",
      "using                                                                                         \n",
      "lgbm                                                                                          \n",
      "  2%|▎                   | 27/1500 [00:47<50:34,  2.06s/trial, best loss: -0.5716923076923076]"
     ]
    }
   ],
   "source": [
    "class HyperoptOptimizer:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.best = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def hyperopt_train_test(self, params):\n",
    "        # Extract RFE parameters\n",
    "        n_features_to_select = params['n_features_to_select']\n",
    "        del params['n_features_to_select']\n",
    "        \n",
    "        # extract classifier type\n",
    "        t = params['type']\n",
    "        del params['type']\n",
    "        \n",
    "        # define classifier based on type            \n",
    "        if t == 'lgbm':\n",
    "            clf = LGBMClassifier(**params)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        # define RFE with the classifier\n",
    "        rfe = RFE(estimator=clf, \n",
    "                  n_features_to_select=n_features_to_select)\n",
    "        \n",
    "        # create LightGBM dataset with categorical features specified\n",
    "        train_data = lgb.Dataset(self.X, label=self.y, categorical_feature=[0, 1, 2, 3, 4, 5])\n",
    "        \n",
    "        # perform cross-validation\n",
    "        return cross_val_score(rfe, self.X, self.y).mean()\n",
    "\n",
    "    def objective(self, params):\n",
    "        self.count += 1\n",
    "        acc = self.hyperopt_train_test(params.copy())\n",
    "        if acc > self.best:\n",
    "            print('new best:', acc, 'using', params['type'])\n",
    "            self.best = acc\n",
    "        if self.count % 250 == 0:\n",
    "            print('iters:', self.count, ', acc:', acc, 'using', params)\n",
    "        return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "# define hyperparameter space\n",
    "space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'lgbm',\n",
    "        'min_data_in_bin': 1,\n",
    "        'min_data_in_leaf': 1,\n",
    "        'verbose': -1,\n",
    "        'boosting_type': hp.choice('boosting_type',['gbdt','dart','rf']),\n",
    "        'n_features_to_select': hp.choice('n_features_to_select', range(1, X_threshold.shape[1]+1)),\n",
    "        'num_leaves': hp.choice('num_leaves', range(10, 150)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "        'n_estimators': hp.choice('n_estimators', range(50, 500)),\n",
    "        'max_depth': hp.choice('max_depth', range(1, 25)),\n",
    "        'min_child_samples': hp.choice('min_child_samples', range(5, 100)),\n",
    "        'subsample': hp.uniform('subsample', 0.15, 1),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.15, 1),\n",
    "        'random_state': seed,\n",
    "        'n_jobs': -1,\n",
    "        'reg_alpha': hp.uniform('reg_alpha',0.01,10),\n",
    "        'reg_lambda': hp.uniform('reg_lambda',0.01,10),\n",
    "        'importance_type': hp.choice('importance_type',['split','gain'])\n",
    "    }\n",
    "])\n",
    "\n",
    "# instantiate optimizer\n",
    "optimizer = HyperoptOptimizer(X_threshold, y)\n",
    "\n",
    "# initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "rstate = np.random.default_rng(seed)\n",
    "\n",
    "# run optimization\n",
    "best = fmin(optimizer.objective, \n",
    "            space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=1500, \n",
    "            trials=trials,\n",
    "            rstate=rstate,\n",
    "            return_argmin=False)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373cfa89-aa26-4185-b193-6c3d27683644",
   "metadata": {},
   "source": [
    "##### Save best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb6791-e5fa-4a4f-811d-3bef0c7b1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41acf12-4c3f-4300-9492-44f04be3c1d8",
   "metadata": {},
   "source": [
    "Save the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64204bcf-c9b2-468b-8734-779fad3d6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# get current date and time\n",
    "current_datetime=datetime.now()\n",
    "\n",
    "# print current date and time to check\n",
    "print(current_datetime)\n",
    "\n",
    "# format the datetime for a filename\n",
    "datetime_suffix=current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# create filename with the datetime suffix\n",
    "file_name=f'../joblib/1_hyperopt_lgbm_bestparams_{datetime_suffix}.json'\n",
    "\n",
    "# save model\n",
    "with open(file_name,'w') as file:\n",
    "    file.write(json.dumps(best,default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae257f2-4c90-47cb-bbcf-2718c2929010",
   "metadata": {},
   "source": [
    "##### Run the best parameters on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b337762-f853-4fab-b600-fa58b889f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract best params file\n",
    "with open(file_name,'r') as file:\n",
    "    best_params=json.load(file)\n",
    "    \n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d1661-a95f-46ae-a5ed-f4be728c4edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract best parameters\n",
    "best_n_features_to_select = best_params['n_features_to_select']\n",
    "del best_params['n_features_to_select']\n",
    "best_type = best_params['type']\n",
    "del best_params['type']\n",
    "\n",
    "# train final model using best parameters\n",
    "if best_type == 'extratrees':\n",
    "    final_clf = ExtraTreesClassifier(**best_params)\n",
    "    \n",
    "# define RFE with final classifier\n",
    "final_rfe = RFE(estimator=final_clf, \n",
    "                n_features_to_select=best_n_features_to_select)\n",
    "\n",
    "# fit final model on entire training set\n",
    "final_rfe.fit(X_train_threshold, y_train_threshold)\n",
    "\n",
    "# evaluate final model on test set\n",
    "final_score = final_rfe.score(X_test_threshold, y_test_threshold)\n",
    "print('Final test score:', final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c680f59-078c-4f7e-a8f2-40a8979ac57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0f9a8-978e-4e28-9524-ab5d5f47f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()[1]/y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abb483-84a3-4e7a-86a9-4afdd441a4e8",
   "metadata": {},
   "source": [
    "Next attempt is adapted from tutorial from [MachineLearningMastery.com](#https://machinelearningmastery.com/hyperopt-for-automated-machine-learning-with-scikit-learn/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24439dca-b6be-4a7c-b245-78035ae6d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_regressor\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ca07a-4f67-4541-8e2e-fa50b42795b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "model = HyperoptEstimator(regressor=any_regressor('reg'), \n",
    "                          preprocessing=any_preprocessing('pre'), \n",
    "                          loss_fn=mean_absolute_error, \n",
    "                          algo=tpe.suggest, \n",
    "                          max_evals=50, \n",
    "                          trial_timeout=30)#,\n",
    "                          # seed=np.random.default_rng(seed))\n",
    "# perform the search\n",
    "model.fit(X_train_threshold, y_train_threshold)#,random_state=np.random.default_rng(seed))\n",
    "# summarize performance\n",
    "mae = model.score(X_test_threshold, y_test_threshold)\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "# summarize the best model\n",
    "print(model.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229e4f1-dae7-4714-bf50-4043b1db910d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27f37d0e-48c4-49ce-959a-5c7d8f5e893e",
   "metadata": {},
   "source": [
    "### Statistical Modeling with `Statsmodels` <a name=\"statistical_modeling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066609a-9201-4692-8149-df8d4041c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da626ed-88df-4928-adc1-bdf5031cd5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and setup dataset again\n",
    "\n",
    "df=pd.read_csv('../data/1_data.csv')\n",
    "\n",
    "# renaming columns to preserve order\n",
    "# and make them more intelligible\n",
    "df.rename(columns={'Y':'y',\n",
    "                   'X1':'a_time',\n",
    "                   'X2':'b_contents',\n",
    "                   'X3':'c_complete',\n",
    "                   'X4':'d_price',\n",
    "                   'X5':'e_courier',\n",
    "                   'X6':'f_app'},inplace=True)\n",
    "\n",
    "X=df[[col for col in df.columns if col != 'y']].copy()\n",
    "y=df['y'].copy().astype('int8') # because it's a binary\n",
    "                                # let's use less memory\n",
    "\n",
    "# print(\"X shape:\",X.shape)\n",
    "# print(\"y shape:\",y.shape)\n",
    "\n",
    "# print(X.dtypes)\n",
    "\n",
    "X_cat=X.copy()\n",
    "\n",
    "for col in X_cat.columns:\n",
    "    X_cat[col] = X_cat[col].astype('category')\n",
    "    \n",
    "# X_cat.dtypes\n",
    "\n",
    "X_ohe=pd.get_dummies(data=X_cat,\n",
    "                     prefix=list(X_cat.columns),\n",
    "                     drop_first=False) # I think we need to \n",
    "                                       # see all survey responses\n",
    "                                       # that are in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794b466-60be-4144-ba7b-12259837932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add constant to our X\n",
    "X_const=sm.add_constant(X_ohe[[col for col in X_ohe.columns if col != 'y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2436467-cc97-4800-af9c-2dff9c4adf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it out\n",
    "X_const.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367c6a6-9bf9-44b4-9d7d-8d3035b72258",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_const.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f0184-46ba-45bb-8489-e52a82944826",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9621f03-1c9b-4ed3-82bc-a877ec7a992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the logistic regression model \n",
    "logreg = sm.Logit(y, X_const)\n",
    "\n",
    "# fit the model\n",
    "logreg_results = logreg.fit()\n",
    "\n",
    "# display the results \n",
    "logreg_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf0a21-b632-428d-9ffd-af746226dc32",
   "metadata": {},
   "source": [
    "PLACEHOLDER TEXT  \n",
    "All features have p-values above 0.05 except time, which is just under the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f51e43-cae8-4535-8c6f-784b00ce9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the model predictions as probabilities \n",
    "# and saving to 'y_proba'\n",
    "y_proba = logreg_results.predict(X_const)\n",
    "\n",
    "# view \n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e00bf8-034b-49a2-b448-7d5c2a05058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume probability >=50%\n",
    "# is a happy customer prediction\n",
    "# so we'll make the soft preds into hard preds\n",
    "y_pred = np.where(y_proba >= 0.5, 1, 0)\n",
    "\n",
    "# look at the model's predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49733a6a-603f-478a-ac13-510de61ad51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "# find where predicted = true survival\n",
    "# then divide by the number of predictions/passengers\n",
    "acc = (y_pred == y).sum()/df.shape[0]\n",
    "\n",
    "# Print the accuracy score\n",
    "print(f'Model accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6baac-a753-4980-adca-bf4b1d075164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put params into a dataframe\n",
    "results_df = pd.DataFrame(logreg_results.params, columns=['Coefficient'])\n",
    "\n",
    "# view the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce8ee4-ad79-4806-8b2e-fc75bd7a421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and add the odds ratios to results_df\n",
    "# log odds is more interpretable\n",
    "results_df['odds_ratio'] = np.exp(results_df['Coefficient'])\n",
    "\n",
    "# display the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4dc69e-d83e-4fc7-b591-0b48751128cb",
   "metadata": {},
   "source": [
    "Each component of the survey shows that it has an impact on the overall happiness of the customer. Time is the largest factor, which makes sense: when you're hungry, you want food as soon as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449df782-1939-4117-b021-be6783c2829c",
   "metadata": {},
   "source": [
    "Given that the p-values of time was the only factor that was below the 0.05 threshold suggests that we should try this again with only time as the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852209d-1dfa-4a9c-8959-05b2663ded8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add constant to our X\n",
    "X_const=sm.add_constant(df[[col for col in df.columns if col != 'y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a5c6e-cd04-4057-83f7-9141809d6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it out\n",
    "X_const=X_const.drop([col for col in X_const.columns if (col !='a_time') or (col !='const')],axis=1)\n",
    "X_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b1dd5-2c33-4fd7-9d87-d5d416006c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the logistic regression model \n",
    "logreg = sm.Logit(y, X_const)\n",
    "\n",
    "# fit the model\n",
    "logreg_results = logreg.fit()\n",
    "\n",
    "# display the results \n",
    "logreg_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a51fe-81fb-474b-8fcc-caec54446a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the model predictions as probabilities \n",
    "# and saving to 'y_proba'\n",
    "y_proba = logreg_results.predict(X_const)\n",
    "\n",
    "# view \n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc671e94-5aeb-41a1-88cd-4ddd4528c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume probability >=50%\n",
    "# is a happy customer prediction\n",
    "# so we'll make the soft preds into hard preds\n",
    "y_pred = np.where(y_proba >= 0.5, 1, 0)\n",
    "\n",
    "# look at the model's predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f3dbf-4021-433a-ba9e-2c2b009a969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "# find where predicted = true survival\n",
    "# then divide by the number of predictions/passengers\n",
    "acc = (y_pred == y).sum()/df.shape[0]\n",
    "\n",
    "# Print the accuracy score\n",
    "print(f'Model accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd015c4-fd22-464b-91c2-37772d627925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put params into a dataframe\n",
    "results_df = pd.DataFrame(logreg_results.params, columns=['Coefficient'])\n",
    "\n",
    "# view the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37319b11-cb6f-4cac-ad69-2fe3c8523a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and add the odds ratios to results_df\n",
    "# log odds is more interpretable\n",
    "results_df['odds_ratio'] = np.exp(results_df['Coefficient'])\n",
    "\n",
    "# display the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ee5cf-5c9e-4c5c-9533-03e6cc082027",
   "metadata": {},
   "source": [
    "Oops, that did not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea03a6c-1aa2-46f7-94b6-736818161198",
   "metadata": {},
   "source": [
    "Apziva: UP2IqAzAWrVBrULk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightgbm",
   "language": "python",
   "name": "lightgbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
